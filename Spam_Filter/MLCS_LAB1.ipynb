{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MLCS_LAB1.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "VhIFe81jO-l8",
        "ugyGJaI9ueJo",
        "ABO5iqrc7QOh",
        "3rVHuTS75ny0",
        "Pv_IcanYBwHa",
        "U3TSwH4h8zYU",
        "xCfFp2XdKQX2"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k65yOiapFAYN"
      },
      "source": [
        "Upload dataset and unzip the file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cs8NKu9G57OB"
      },
      "source": [
        "!tar xzf lingspam_public.tar.gz"
      ],
      "execution_count": 489,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ERgexGVFJbr"
      },
      "source": [
        "Import library"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oU1WboU8FN7Z"
      },
      "source": [
        "from decimal import *\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import math\n",
        "import os\n",
        "from collections import Counter\n",
        "from collections import OrderedDict\n",
        "from sklearn import svm"
      ],
      "execution_count": 490,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W3Xkmu4yIEB-"
      },
      "source": [
        "Load words in emails into a word list."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xieXBtvMIfDO"
      },
      "source": [
        "train_path = './lingspam_public/lemm_stop'  # parent directory of dataset we use\n",
        "paths = [os.path.join(train_path, folders) for folders in os.listdir(train_path)]  \n",
        "all_words = [] \n",
        "labels = []  # 1 for spam, 0 for legit\n",
        "test_path = \"\"\n",
        "for path in paths:\n",
        "    if(path[-2:] == '10'):  # path[-2:] check if this is part10 which is used for testing, skip \n",
        "        test_path = path\n",
        "        continue\n",
        "    files = [os.path.join(path, f) for f in os.listdir(path)]  # get file names of this part and generate path to files\n",
        "    for email in files:\n",
        "        if(email.find('spmsg') != -1): #check filenames to check if it is spam \n",
        "            labels.append(1)\n",
        "        else:\n",
        "            labels.append(0)\n",
        "        \n",
        "        with open(email) as m:\n",
        "            for i, content in enumerate(m):  # i: line number , content: content of each line\n",
        "                if(i == 2):  # open txt and find content is in the 3rd line\n",
        "                    words = content.split()\n",
        "                    all_words += words\n",
        "\n",
        "word_dict = Counter(all_words)  \n",
        "\n",
        "# remove symbols which have no big relationship with spam or legit\n",
        "for word in list(word_dict.keys()):\n",
        "    if(word.isalpha() == False):\n",
        "        del word_dict[word]\n",
        "\n",
        "# distinct words\n",
        "dist_words = list(word_dict.keys())"
      ],
      "execution_count": 491,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VhIFe81jO-l8"
      },
      "source": [
        "# Compute Information Gain(IG)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b0GhfsNXPbkN"
      },
      "source": [
        "1. compute H(C), C is RV that determins if a document is spam or legit "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iDTeFjktPDqW",
        "outputId": "0ac5cf46-91db-49ea-c66d-9de0e2470f26",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "spam = 0\n",
        "legit = 0\n",
        "for label in labels:\n",
        "  if label == 1:\n",
        "    spam += 1\n",
        "  else:\n",
        "    legit += 1  \n",
        "\n",
        "print(f\"spam email: {spam}, legit email: {legit}, total email {spam + legit}\")\n",
        "p_spam = spam / (spam + legit)\n",
        "\n",
        "H_c = -1 * ( p_spam*np.log2(p_spam) + (1-p_spam)*np.log2(1-p_spam) )\n",
        "print('H(C): ', H_c)"
      ],
      "execution_count": 492,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "spam email: 432, legit email: 2170, total email 2602\n",
            "H(C):  0.6485330171848536\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cQL0u-2ES0nq"
      },
      "source": [
        "2. Compute H(C|Xi), need to create dictionary for word:#spam and word:#legit to help computing H(C|Xi) "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BPJMmsbETNSW"
      },
      "source": [
        "word_spam = {}\n",
        "word_legit = {}\n",
        "for word in dist_words:\n",
        "    word_spam[word] = 0\n",
        "    word_legit[word] = 0\n",
        "\n",
        "for path in paths:\n",
        "    if(path[-2:] == '10'):  \n",
        "        continue\n",
        "    files = [os.path.join(path, f) for f in os.listdir(path)]  \n",
        "    for email in files:\n",
        "        if(email.find('spmsg') != -1):  \n",
        "            is_spam = True\n",
        "        else:\n",
        "            is_spam = False\n",
        "        dist_set = set() # there could be repeated word, we only need  occurance, use set\n",
        "        with open(email) as m:\n",
        "            for i, content in enumerate(m):  \n",
        "                if(i == 2):  \n",
        "                    words = content.split()\n",
        "                    for word in words:\n",
        "                        if(word.isalpha() == False): # skip symbols\n",
        "                            continue\n",
        "                        else:\n",
        "                            dist_set.add(word)\n",
        "        for e in dist_set:\n",
        "            if(is_spam == True):\n",
        "                word_spam[e] += 1\n",
        "            else:\n",
        "                word_legit[e] += 1"
      ],
      "execution_count": 493,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ueAdkOy3mB0I"
      },
      "source": [
        "Compute H(C|Xi) = \"combination\" of P(X=x,C=c)log(P(C=c|X=x))"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ELU0DEIuV3Yl"
      },
      "source": [
        "H_cx = {}\n",
        "for word in dist_words:\n",
        "    H_cx[word] = 0 \n",
        "    # c = legit, x = 0 \n",
        "    if ((legit - word_legit[word]) != 0 and (spam - word_spam[word] + legit - word_legit[word]) != 0): #sum only when non-zero probability\n",
        "        H_cx[word] += -1 * (legit - word_legit[word]) / (spam + legit) * np.log2( (legit - word_legit[word]) / (spam - word_spam[word] + legit - word_legit[word]) )\n",
        "    # c = legit, x = 1 \n",
        "    if ((word_legit[word]) != 0 and (word_spam[word] + word_legit[word]) != 0):\n",
        "        H_cx[word] += -1 * (word_legit[word]) / (spam + legit) * np.log2( word_legit[word] / (word_spam[word] + word_legit[word]) )\n",
        "    # c = spam, x = 0 \n",
        "    if (spam-word_spam[word] != 0 and (spam - word_spam[word] + legit - word_legit[word]) != 0):\n",
        "        H_cx[word] += -1 * (spam - word_spam[word]) / (spam + legit) * np.log2( (spam - word_spam[word] ) / (spam - word_spam[word] + legit - word_legit[word]) ) \n",
        "    # c = spam, x = 1 \n",
        "    if (word_spam[word] != 0 and word_spam[word] + word_legit[word] != 0):\n",
        "        H_cx[word] += -1 * (word_spam[word]) / (spam + legit) * np.log2( word_spam[word] / (word_spam[word] + word_legit[word]) ) \n",
        "        "
      ],
      "execution_count": 494,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J1NkCKOetVna"
      },
      "source": [
        "3. Compute IG"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_F0ML3Y0tYqm"
      },
      "source": [
        "IG = {}\n",
        "for word in list(H_cx.keys()):\n",
        "    IG[word] = H_c - H_cx[word]"
      ],
      "execution_count": 495,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ugyGJaI9ueJo"
      },
      "source": [
        "# Get top N features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q0A-Dh_Euh1e"
      },
      "source": [
        "# sort by value\n",
        "# sorted can be applied to iterable containers\n",
        "# sorted return a new result rather than sort in place\n",
        "# sorted return a list object not a sorted dictionary!!!!!!!\n",
        "# sorted_IG = sorted(IG.items(), key=lambda x : x[1], reverse=True)\n",
        "sorted_IG = OrderedDict(sorted(IG.items(), key=lambda x : x[1], reverse=True))\n",
        "f10 = list(sorted_IG.keys())[:10]  # top 10\n",
        "f100 = list(sorted_IG.keys())[:100]  # top 100\n",
        "f1000 = list(sorted_IG.keys())[:1000]  # top 1000"
      ],
      "execution_count": 496,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wmnBC0_n-hpX"
      },
      "source": [
        "# Part1 report: top-10 words:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FizqAdvI-o_X",
        "outputId": "1534977d-8ba7-4bf8-d0c6-82208d5ee5d4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 209
        }
      },
      "source": [
        "print(\"Top-10 words:\")\n",
        "c=0\n",
        "for i in sorted_IG.items():\n",
        "  c+=1\n",
        "  if c > 10:\n",
        "    break\n",
        "  print(i[0],\":\",i[1])"
      ],
      "execution_count": 497,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Top-10 words:\n",
            "language : 0.19967490044495867\n",
            "remove : 0.16891307295882557\n",
            "free : 0.15997268664519282\n",
            "linguistic : 0.1462359533473594\n",
            "university : 0.1450067285566311\n",
            "money : 0.11867735600192031\n",
            "click : 0.10117445536770531\n",
            "market : 0.09149985619225265\n",
            "our : 0.08706843935925757\n",
            "business : 0.08301653103351447\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ABO5iqrc7QOh"
      },
      "source": [
        "# Bernoulli NB classifier with binary feature"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Crq3xhFM93xS"
      },
      "source": [
        "*Load test data*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JNMvb-aI7uBx"
      },
      "source": [
        "test_label = []  \n",
        "f10_test_bbf = []  # test emails' feature matrix for top 10\n",
        "f100_test_bbf = []  # test emails' feature matrix for top 100\n",
        "f1000_test_bbf = []  # test emails' feature matrix for top 1000\n",
        "emails = [os.path.join(test_path, file_name) for file_name in os.listdir(test_path)]  \n",
        "for email in emails:\n",
        "    # spam: 1, legit: 0\n",
        "    if email.find('spmsg')!=-1:\n",
        "        test_label.append(1)\n",
        "    else:\n",
        "        test_label.append(0)\n",
        "    \n",
        "    with open(email) as m:\n",
        "        temp_f10_bf = []\n",
        "        temp_f100_bf = []\n",
        "        temp_f1000_bf = []\n",
        "\n",
        "        for i, content in enumerate(m):  \n",
        "            if i==2:  # content at 3rd line\n",
        "                words_in_email = set(content.split())\n",
        "                for w in f10:\n",
        "                    if w in words_in_email:\n",
        "                        temp_f10_bf.append(1)\n",
        "                    else:\n",
        "                        temp_f10_bf.append(0)\n",
        "                for w in f100:\n",
        "                    if w in words_in_email:\n",
        "                        temp_f100_bf.append(1)\n",
        "                    else:\n",
        "                        temp_f100_bf.append(0)\n",
        "                for w in f1000:\n",
        "                    if w in words_in_email:\n",
        "                        temp_f1000_bf.append(1)\n",
        "                    else:\n",
        "                        temp_f1000_bf.append(0)\n",
        "\n",
        "        f10_test_bbf.append(temp_f10_bf)\n",
        "        f100_test_bbf.append(temp_f100_bf)\n",
        "        f1000_test_bbf.append(temp_f1000_bf)\n"
      ],
      "execution_count": 498,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LiaK3Ka-7zk8"
      },
      "source": [
        "**1. top 10 feature**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aIwbYtuC0q3f"
      },
      "source": [
        "N = 10"
      ],
      "execution_count": 499,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "niYy7de7-RYx"
      },
      "source": [
        "1.1 Compute probability"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NZHI_lEp-Pry"
      },
      "source": [
        "# x is conbination of words\n",
        "# compute P(x|spam)\n",
        "p_x_spam_10 = []\n",
        "for case in f10_test_bbf:\n",
        "    p = 1\n",
        "    for i in range(N):\n",
        "        if case[i] == 1:\n",
        "            p *= (word_spam[f10[i]] + 1) / (spam + 2) # with laplacian smoothing\n",
        "        else:\n",
        "            p *= (1 - (word_spam[f10[i]] + 1) / (spam + 2)) # with laplacian smoothing\n",
        "    p_x_spam_10.append(p)    \n",
        "\n",
        "# compute P(x|legit)\n",
        "p_x_legit_10 = []\n",
        "for case in f10_test_bbf:\n",
        "    p = 1\n",
        "    for i in range(N):\n",
        "        if case[i] == 1:\n",
        "            p *= (word_legit[f10[i]] + 1) / (legit + 2) # with laplacian smoothing\n",
        "        else:\n",
        "            p *= 1 - (word_legit[f10[i]] + 1) / (legit + 2) # with laplacian smoothing\n",
        "    p_x_legit_10.append(p)    \n",
        "\n",
        "# compute P(spam)\n",
        "p_spam = spam/(spam+legit)\n",
        "\n",
        "# compute P(legit)\n",
        "p_legit = legit/(spam+legit) \n",
        "\n",
        "# compute P(x)\n",
        "p_x_10 = []\n",
        "for i in range(len(f10_test_bbf)):\n",
        "    p = p_spam * p_x_spam_10[i] + p_legit * p_x_legit_10[i]\n",
        "    p_x_10.append(p)\n",
        " \n",
        "  "
      ],
      "execution_count": 500,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FJZSqca5P62I"
      },
      "source": [
        "1.2 Classify by computing P(spam|X) and P(legit|X) and compare"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O-OyxzunQHRe"
      },
      "source": [
        "f10_pre = []\n",
        "p_spam_x_10 = []\n",
        "p_legit_x_10 = []\n",
        "for i in range(len(f10_test_bbf)):\n",
        "    psx = p_x_spam_10[i] * p_spam / p_x_10[i]\n",
        "    p_spam_x_10.append(psx)\n",
        "    plx = p_x_legit_10[i] * p_legit / p_x_10[i]\n",
        "    p_legit_x_10.append(plx)\n",
        "    if psx >= plx :\n",
        "        f10_pre.append(1)\n",
        "    else:\n",
        "        f10_pre.append(0)"
      ],
      "execution_count": 501,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FYOER96_xpUr"
      },
      "source": [
        "1.3 Report result"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FDo9E8_lgiFh",
        "outputId": "67451971-c0c6-4bf6-d708-54e55b35bc61",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "test_label[:10]"
      ],
      "execution_count": 502,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 502
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yDc4MZBNgqFp",
        "outputId": "159efe57-b989-4742-cf84-45d248c252e9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "f10_pre[:10]"
      ],
      "execution_count": 503,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 503
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_uw3zJXWiY4C"
      },
      "source": [
        "#p_spam_x_10[:10]"
      ],
      "execution_count": 504,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cyandbE6ifiI"
      },
      "source": [
        "#p_legit_x_10[:10]"
      ],
      "execution_count": 505,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GjhBOpR3R-dA",
        "outputId": "fe6dabec-58c6-4c39-8e9d-5ddcfec2d032",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "correct = 0;\n",
        "total = len(test_label)\n",
        "for i in range(total):\n",
        "    if test_label[i] == f10_pre[i]:\n",
        "        correct+=1\n",
        "correct_rate = correct / total\n",
        "print(\"correct rate: \",correct_rate)\n",
        "\n",
        "# spam precision is defined as the fraction of true spam e-mails among all e-mails predicted as spam\n",
        "total_pre_spam = 0\n",
        "true_spam_in_spam = 0\n",
        "for i in range(total):\n",
        "    if f10_pre[i] == 1:\n",
        "        total_pre_spam += 1\n",
        "        if test_label[i] == 1:\n",
        "            true_spam_in_spam += 1\n",
        "spam_precision_bbf_10 = true_spam_in_spam / total_pre_spam   \n",
        "print(\"spam precision: \",spam_precision_bbf_10)\n",
        "\n",
        "# spam recall is defined as fraction of true spam e-mails predicted as spam.\n",
        "pre_spam_in_true = 0\n",
        "total_true_spam = 0\n",
        "for i in range(total):\n",
        "    if test_label[i] == 1:\n",
        "        total_true_spam += 1\n",
        "        if f10_pre[i] == 1:\n",
        "            pre_spam_in_true += 1\n",
        "        \n",
        "spam_recall_bbf_10 = pre_spam_in_true / total_true_spam  \n",
        "print(\"spam_recall: \",spam_recall_bbf_10)"
      ],
      "execution_count": 506,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "correct rate:  0.9518900343642611\n",
            "spam precision:  0.8888888888888888\n",
            "spam_recall:  0.8163265306122449\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pwMSSJRZwTM-"
      },
      "source": [
        "**2. top 100 feature**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oNZPV-rZwewD"
      },
      "source": [
        "N = 100"
      ],
      "execution_count": 507,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xe5bXPQ0w2pX"
      },
      "source": [
        "2.1 Compute probability"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "00OIfvVBw1uO"
      },
      "source": [
        "# x is conbination of words\n",
        "# compute P(x|spam)\n",
        "p_x_spam_100 = []\n",
        "for case in f100_test_bbf:\n",
        "    p = 1\n",
        "    for i in range(N):\n",
        "        if case[i] == 1:\n",
        "            p *= (word_spam[f100[i]] + 1) / (spam + 2) # with laplacian smoothing\n",
        "        else:\n",
        "            p *= (1 - (word_spam[f100[i]] + 1) / (spam + 2)) # with laplacian smoothing\n",
        "    p_x_spam_100.append(p)    \n",
        "\n",
        "# compute P(x|legit)\n",
        "p_x_legit_100 = []\n",
        "for case in f100_test_bbf:\n",
        "    p = 1\n",
        "    for i in range(N):\n",
        "        if case[i] == 1:\n",
        "            p *= (word_legit[f100[i]] + 1) / (legit + 2) # with laplacian smoothing\n",
        "        else:\n",
        "            p *= 1 - (word_legit[f100[i]] + 1) / (legit + 2) # with laplacian smoothing\n",
        "    p_x_legit_100.append(p)    \n",
        "\n",
        "# compute P(spam)\n",
        "p_spam = spam/(spam+legit)\n",
        "\n",
        "# compute P(legit)\n",
        "p_legit = legit/(spam+legit) \n",
        "\n",
        "# compute P(x)\n",
        "p_x_100 = []\n",
        "for i in range(len(f100_test_bbf)):\n",
        "    p = p_spam * p_x_spam_100[i] + p_legit * p_x_legit_100[i]\n",
        "    p_x_100.append(p)\n",
        " \n",
        "#print(len(p_x_spam_100))\n",
        "#print(len(p_x_100))"
      ],
      "execution_count": 508,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fQH1KvwzxOJI"
      },
      "source": [
        "2.2 Classify by computing P(spam|X) and P(legit|X) and compare"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1oXWJ58JxOkA"
      },
      "source": [
        "f100_pre = []\n",
        "p_spam_x_100 = []\n",
        "p_legit_x_100 = []\n",
        "for i in range(len(f100_test_bbf)):\n",
        "    psx = p_x_spam_100[i] * p_spam / p_x_100[i]\n",
        "    p_spam_x_100.append(psx)\n",
        "    plx = p_x_legit_100[i] * p_legit / p_x_100[i]\n",
        "    p_legit_x_100.append(plx)\n",
        "    if psx >= plx :\n",
        "        f100_pre.append(1)\n",
        "    else:\n",
        "        f100_pre.append(0)"
      ],
      "execution_count": 509,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ETjJabOxvq5"
      },
      "source": [
        "2.3 Report result"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UvnZy0F5xjkN",
        "outputId": "f25cb16c-05ae-48ef-a867-9d062cdfb77a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "test_label[:10]"
      ],
      "execution_count": 510,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 510
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7VKPQw0qxkEW",
        "outputId": "adc098a0-27f1-4b89-d402-9e7f948a9dfd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "f100_pre[:10]"
      ],
      "execution_count": 511,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 511
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o5kNlR6cxm4C",
        "outputId": "86de9753-4ee3-4f2d-8346-a960182bf5a5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "correct = 0;\n",
        "total = len(test_label)\n",
        "for i in range(total):\n",
        "    if test_label[i] == f100_pre[i]:\n",
        "        correct+=1\n",
        "correct_rate = correct / total\n",
        "print(\"correct rate: \",correct_rate)\n",
        "\n",
        "# spam precision is defined as the fraction of true spam e-mails among all e-mails predicted as spam\n",
        "total_pre_spam = 0\n",
        "true_spam_in_spam = 0\n",
        "for i in range(total):\n",
        "    if f100_pre[i] == 1:\n",
        "        total_pre_spam += 1\n",
        "        if test_label[i] == 1:\n",
        "            true_spam_in_spam += 1\n",
        "spam_precision_bbf_100 = true_spam_in_spam / total_pre_spam   \n",
        "print(\"spam precision: \",spam_precision_bbf_100)\n",
        "\n",
        "# spam recall is defined as fraction of true spam e-mails predicted as spam.\n",
        "pre_spam_in_true = 0\n",
        "total_true_spam = 0\n",
        "for i in range(total):\n",
        "    if test_label[i] == 1:\n",
        "        total_true_spam += 1\n",
        "        if f100_pre[i] == 1:\n",
        "            pre_spam_in_true += 1\n",
        "        \n",
        "spam_recall_bbf_100 = pre_spam_in_true / total_true_spam  \n",
        "print(\"spam_recall: \",spam_recall_bbf_100)"
      ],
      "execution_count": 512,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "correct rate:  0.9450171821305842\n",
            "spam precision:  1.0\n",
            "spam_recall:  0.673469387755102\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zsevyVZJzmIq"
      },
      "source": [
        "3. top 100 feature\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qdZpVBoc2C3K"
      },
      "source": [
        "N = 1000"
      ],
      "execution_count": 513,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3dmZt81Uzowe"
      },
      "source": [
        "**3.1 Compute probability**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "31t4DlcFzpug"
      },
      "source": [
        "# x is conbination of words\n",
        "# compute P(x|spam)\n",
        "p_x_spam_1000 = []\n",
        "for case in f1000_test_bbf:\n",
        "    p = 1\n",
        "    for i in range(N):\n",
        "        if case[i] == 1:\n",
        "            p *= (word_spam[f1000[i]] + 1) / (spam + 2) # with laplacian smoothing\n",
        "        else:\n",
        "            p *= (1 - (word_spam[f1000[i]] + 1) / (spam + 2)) # with laplacian smoothing\n",
        "    p_x_spam_1000.append(p)    \n",
        "\n",
        "# compute P(x|legit)\n",
        "p_x_legit_1000 = []\n",
        "for case in f1000_test_bbf:\n",
        "    p = 1\n",
        "    for i in range(N):\n",
        "        if case[i] == 1:\n",
        "            p *= (word_legit[f1000[i]] + 1) / (legit + 2) # with laplacian smoothing\n",
        "        else:\n",
        "            p *= 1 - (word_legit[f1000[i]] + 1) / (legit + 2) # with laplacian smoothing\n",
        "    p_x_legit_1000.append(p)    \n",
        "\n",
        "# compute P(spam)\n",
        "p_spam = spam/(spam+legit)\n",
        "\n",
        "# compute P(legit)\n",
        "p_legit = legit/(spam+legit) \n",
        "\n",
        "# compute P(x)\n",
        "p_x_1000 = []\n",
        "for i in range(len(f1000_test_bbf)):\n",
        "    p = p_spam * p_x_spam_1000[i] + p_legit * p_x_legit_1000[i]\n",
        "    p_x_1000.append(p)\n",
        " \n",
        "#print(len(p_x_spam_1000))\n",
        "#print(len(p_x_1000))"
      ],
      "execution_count": 514,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j1vuFmrMztss"
      },
      "source": [
        "3.2 Classify by computing P(spam|X) and P(legit|X) and compare"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2w0oC6o52W5Y"
      },
      "source": [
        "f1000_pre = []\n",
        "p_spam_x_1000 = []\n",
        "p_legit_x_1000 = []\n",
        "for i in range(len(f1000_test_bbf)):\n",
        "    psx = p_x_spam_1000[i] * p_spam / p_x_1000[i]\n",
        "    p_spam_x_1000.append(psx)\n",
        "    plx = p_x_legit_1000[i] * p_legit / p_x_1000[i]\n",
        "    p_legit_x_1000.append(plx)\n",
        "    if psx >= plx :\n",
        "        f1000_pre.append(1)\n",
        "    else:\n",
        "        f1000_pre.append(0)"
      ],
      "execution_count": 515,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RXlTeufM2iix"
      },
      "source": [
        "3.3 Report result"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oK2ph62B2nNJ",
        "outputId": "af036964-58a2-476e-f6e4-58d4c5aa0f10",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "test_label[:10]"
      ],
      "execution_count": 516,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 516
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a8W801_y2nA7",
        "outputId": "c9ccde20-4caf-4460-ec6d-b67952ef9f09",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "f1000_pre[:10]"
      ],
      "execution_count": 517,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 517
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "907cHKZS2mIa",
        "outputId": "2bea8537-49fb-4a49-e848-e82fac8c71d9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "correct = 0;\n",
        "total = len(test_label)\n",
        "for i in range(total):\n",
        "    if test_label[i] == f1000_pre[i]:\n",
        "        correct+=1\n",
        "correct_rate = correct / total\n",
        "print(\"correct rate: \",correct_rate)\n",
        "\n",
        "# spam precision is defined as the fraction of true spam e-mails among all e-mails predicted as spam\n",
        "total_pre_spam = 0\n",
        "true_spam_in_spam = 0\n",
        "for i in range(total):\n",
        "    if f1000_pre[i] == 1:\n",
        "        total_pre_spam += 1\n",
        "        if test_label[i] == 1:\n",
        "            true_spam_in_spam += 1\n",
        "spam_precision_bbf_1000 = true_spam_in_spam / total_pre_spam   \n",
        "print(\"spam precision: \",spam_precision_bbf_1000)\n",
        "\n",
        "# spam recall is defined as fraction of true spam e-mails predicted as spam.\n",
        "pre_spam_in_true = 0\n",
        "total_true_spam = 0\n",
        "for i in range(total):\n",
        "    if test_label[i] == 1:\n",
        "        total_true_spam += 1\n",
        "        if f1000_pre[i] == 1:\n",
        "            pre_spam_in_true += 1\n",
        "        \n",
        "spam_recall_bbf_1000 = pre_spam_in_true / total_true_spam  \n",
        "print(\"spam_recall: \",spam_recall_bbf_1000)"
      ],
      "execution_count": 518,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "correct rate:  0.9347079037800687\n",
            "spam precision:  1.0\n",
            "spam_recall:  0.6122448979591837\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m2BtjXNA2-dl"
      },
      "source": [
        "***It seems that spam precision goes up while spam recall goes down with more feature selected***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3rVHuTS75ny0"
      },
      "source": [
        "# Multinomial NB with binary features"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hXo6_AyE5xC-"
      },
      "source": [
        "*Load test data*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2NAeOPl151x0"
      },
      "source": [
        "test_label = []  \n",
        "f10_test_mbf = []  # test emails' feature matrix for top 10\n",
        "f100_test_mbf = []  # test emails' feature matrix for top 100\n",
        "f1000_test_mbf = []  # test emails' feature matrix for top 1000\n",
        "emails = [os.path.join(test_path, file_name) for file_name in os.listdir(test_path)]  \n",
        "for email in emails:\n",
        "    # spam: 1, legit: 0\n",
        "    if email.find('spmsg')!=-1:\n",
        "        test_label.append(1)\n",
        "    else:\n",
        "        test_label.append(0)\n",
        "    \n",
        "    with open(email) as m:\n",
        "        temp_f10_bf = []\n",
        "        temp_f100_bf = []\n",
        "        temp_f1000_bf = []\n",
        "\n",
        "        for i, content in enumerate(m):  \n",
        "            if i==2:  # content at 3rd line\n",
        "                words_in_email = set(content.split())\n",
        "                for w in f10:\n",
        "                    if w in words_in_email:\n",
        "                        temp_f10_bf.append(1)\n",
        "                    else:\n",
        "                        temp_f10_bf.append(0)\n",
        "                for w in f100:\n",
        "                    if w in words_in_email:\n",
        "                        temp_f100_bf.append(1)\n",
        "                    else:\n",
        "                        temp_f100_bf.append(0)\n",
        "                for w in f1000:\n",
        "                    if w in words_in_email:\n",
        "                        temp_f1000_bf.append(1)\n",
        "                    else:\n",
        "                        temp_f1000_bf.append(0)\n",
        "\n",
        "        f10_test_mbf.append(temp_f10_bf)\n",
        "        f100_test_mbf.append(temp_f100_bf)\n",
        "        f1000_test_mbf.append(temp_f1000_bf)\n"
      ],
      "execution_count": 519,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w0u5_t2d6n6T"
      },
      "source": [
        "**1. top 10 feature**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lVfqPrOE65JS"
      },
      "source": [
        "N = 10"
      ],
      "execution_count": 520,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0S8clSWd6xOt"
      },
      "source": [
        "1.1 Compute probability"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O72RtLXr8eM1"
      },
      "source": [
        "# compute P(x|spam)\n",
        "p_x_spam_10 = []\n",
        "for case in f10_test_mbf:\n",
        "    p = 1\n",
        "    for i in range(N):\n",
        "        if case[i] == 1:\n",
        "            p *= (word_spam[f10[i]] + 1) / (spam + 2) # with laplacian smoothing\n",
        "        else:\n",
        "            p *= 1 # different from bernoulli: ignore negative evidence\n",
        "    p_x_spam_10.append(p)    \n",
        "\n",
        "# compute P(x|legit)\n",
        "p_x_legit_10 = []\n",
        "for case in f10_test_mbf:\n",
        "    p = 1\n",
        "    for i in range(N):\n",
        "        if case[i] == 1:\n",
        "            p *= (word_legit[f10[i]] + 1) / (legit + 2) # with laplacian smoothing\n",
        "        else:\n",
        "            p *= 1 # different from bernoulli: ignore negative evidence\n",
        "    p_x_legit_10.append(p)    \n",
        "\n",
        "# compute P(spam)\n",
        "p_spam = spam/(spam+legit)\n",
        "\n",
        "# compute P(legit)\n",
        "p_legit = legit/(spam+legit) \n",
        "\n",
        "# compute P(x)\n",
        "p_x_10 = []\n",
        "for i in range(len(f10_test_mbf)):\n",
        "    p = p_spam * p_x_spam_10[i] + p_legit * p_x_legit_10[i]\n",
        "    p_x_10.append(p)\n",
        " \n",
        "#print(len(p_x_spam_10))\n",
        "#print(len(p_x_10))"
      ],
      "execution_count": 521,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iQIN8ySo86s8"
      },
      "source": [
        "1.2 Classify by computing P(spam|X) and P(legit|X) and compare"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C8ToqLaM819w"
      },
      "source": [
        "f10_pre = []\n",
        "p_spam_x_10 = []\n",
        "p_legit_x_10 = []\n",
        "for i in range(len(f10_test_mbf)):\n",
        "    psx = p_x_spam_10[i] * p_spam / p_x_10[i]\n",
        "    p_spam_x_10.append(psx)\n",
        "    plx = p_x_legit_10[i] * p_legit / p_x_10[i]\n",
        "    p_legit_x_10.append(plx)\n",
        "    if psx >= plx :\n",
        "        f10_pre.append(1)\n",
        "    else:\n",
        "        f10_pre.append(0)"
      ],
      "execution_count": 522,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f_AQtKlJ9RsI"
      },
      "source": [
        "1.3 report result"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CqLZMVhc9T4g",
        "outputId": "674e2640-0274-4b4d-bee7-881e54d6dfb6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "correct = 0;\n",
        "total = len(test_label)\n",
        "for i in range(total):\n",
        "    if test_label[i] == f10_pre[i]:\n",
        "        correct+=1\n",
        "correct_rate = correct / total\n",
        "print(\"correct rate: \",correct_rate)\n",
        "\n",
        "# spam precision is defined as the fraction of true spam e-mails among all e-mails predicted as spam\n",
        "total_pre_spam = 0\n",
        "true_spam_in_spam = 0\n",
        "for i in range(total):\n",
        "    if f10_pre[i] == 1:\n",
        "        total_pre_spam += 1\n",
        "        if test_label[i] == 1:\n",
        "            true_spam_in_spam += 1\n",
        "spam_precision_mbf_10 = true_spam_in_spam / total_pre_spam   \n",
        "print(\"spam precision: \",spam_precision_mbf_10)\n",
        "\n",
        "# spam recall is defined as fraction of true spam e-mails predicted as spam.\n",
        "pre_spam_in_true = 0\n",
        "total_true_spam = 0\n",
        "for i in range(total):\n",
        "    if test_label[i] == 1:\n",
        "        total_true_spam += 1\n",
        "        if f10_pre[i] == 1:\n",
        "            pre_spam_in_true += 1\n",
        "        \n",
        "spam_recall_mbf_10 = pre_spam_in_true / total_true_spam  \n",
        "print(\"spam_recall: \",spam_recall_mbf_10)"
      ],
      "execution_count": 523,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "correct rate:  0.9484536082474226\n",
            "spam precision:  0.8695652173913043\n",
            "spam_recall:  0.8163265306122449\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ialsdA4I-s8g"
      },
      "source": [
        "**2. top 100 feature**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O8-zenZu-ypl"
      },
      "source": [
        "N = 100"
      ],
      "execution_count": 524,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9PgiOqFN-0LT"
      },
      "source": [
        "2.1 Compute probability"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZK6g1RHS60Gd"
      },
      "source": [
        "# compute P(x|spam)\n",
        "p_x_spam_100 = []\n",
        "for case in f100_test_mbf:\n",
        "    p = 1\n",
        "    for i in range(N):\n",
        "        if case[i] == 1:\n",
        "            p *= (word_spam[f100[i]] + 1) / (spam + 2) # with laplacian smoothing\n",
        "        else:\n",
        "            p *= 1 # different from bernoulli: ignore negative evidence \n",
        "    p_x_spam_100.append(p)    \n",
        "\n",
        "# compute P(x|legit)\n",
        "p_x_legit_100 = []\n",
        "for case in f100_test_mbf:\n",
        "    p = 1\n",
        "    for i in range(N):\n",
        "        if case[i] == 1:\n",
        "            p *= (word_legit[f100[i]] + 1) / (legit + 2) # with laplacian smoothing\n",
        "        else:\n",
        "            p *= 1 # different from bernoulli: ignore negative evidence\n",
        "    p_x_legit_100.append(p)    \n",
        "\n",
        "# compute P(spam)\n",
        "p_spam = spam/(spam+legit)\n",
        "\n",
        "# compute P(legit)\n",
        "p_legit = legit/(spam+legit) \n",
        "\n",
        "# compute P(x)\n",
        "p_x_100 = []\n",
        "for i in range(len(f100_test_mbf)):\n",
        "    p = p_spam * p_x_spam_100[i] + p_legit * p_x_legit_100[i]\n",
        "    p_x_100.append(p)\n",
        " \n",
        "#print(len(p_x_spam_100))\n",
        "#print(len(p_x_100))"
      ],
      "execution_count": 525,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AforCSgK_C82"
      },
      "source": [
        "2.2 Classify by computing P(spam|X) and P(legit|X) and compare"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RQrF0xKv-98S"
      },
      "source": [
        "f100_pre = []\n",
        "p_spam_x_100 = []\n",
        "p_legit_x_100 = []\n",
        "for i in range(len(f100_test_mbf)):\n",
        "    psx = p_x_spam_100[i] * p_spam / p_x_100[i]\n",
        "    p_spam_x_10.append(psx)\n",
        "    plx = p_x_legit_100[i] * p_legit / p_x_100[i]\n",
        "    p_legit_x_100.append(plx)\n",
        "    if psx >= plx :\n",
        "        f100_pre.append(1)\n",
        "    else:\n",
        "        f100_pre.append(0)"
      ],
      "execution_count": 526,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cg3AOwKG_HvD"
      },
      "source": [
        "2.3 Report result"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Amn-vgkN9dNk",
        "outputId": "d90921cf-61cd-41e0-bd4c-26209b5703a8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "correct = 0;\n",
        "total = len(test_label)\n",
        "for i in range(total):\n",
        "    if test_label[i] == f100_pre[i]:\n",
        "        correct+=1\n",
        "correct_rate = correct / total\n",
        "print(\"correct rate: \",correct_rate)\n",
        "\n",
        "# spam precision is defined as the fraction of true spam e-mails among all e-mails predicted as spam\n",
        "total_pre_spam = 0\n",
        "true_spam_in_spam = 0\n",
        "for i in range(total):\n",
        "    if f100_pre[i] == 1:\n",
        "        total_pre_spam += 1\n",
        "        if test_label[i] == 1:\n",
        "            true_spam_in_spam += 1\n",
        "spam_precision_mbf_100 = true_spam_in_spam / total_pre_spam   \n",
        "print(\"spam precision: \",spam_precision_mbf_100)\n",
        "\n",
        "# spam recall is defined as fraction of true spam e-mails predicted as spam.\n",
        "pre_spam_in_true = 0\n",
        "total_true_spam = 0\n",
        "for i in range(total):\n",
        "    if test_label[i] == 1:\n",
        "        total_true_spam += 1\n",
        "        if f100_pre[i] == 1:\n",
        "            pre_spam_in_true += 1\n",
        "        \n",
        "spam_recall_mbf_100 = pre_spam_in_true / total_true_spam  \n",
        "print(\"spam_recall: \",spam_recall_mbf_100)"
      ],
      "execution_count": 527,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "correct rate:  0.9759450171821306\n",
            "spam precision:  0.9038461538461539\n",
            "spam_recall:  0.9591836734693877\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j12h09bG_jJH"
      },
      "source": [
        "**3. top 1000 feature**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "93RmRmJm_mQ_"
      },
      "source": [
        "N = 1000"
      ],
      "execution_count": 528,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zb-r4yAG_naY"
      },
      "source": [
        "3.1 Compute probability"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qhsVud3j_qBT"
      },
      "source": [
        "# compute P(x|spam)\n",
        "p_x_spam_1000 = []\n",
        "for case in f1000_test_mbf:\n",
        "    p = 1\n",
        "    for i in range(N):\n",
        "        if case[i] == 1:\n",
        "            p *= (word_spam[f1000[i]] + 1) / (spam + 2) # with laplacian smoothing\n",
        "        else:\n",
        "            p *= 1 # different from bernoulli: ignore negative evidence \n",
        "    p_x_spam_1000.append(p)    \n",
        "\n",
        "# compute P(x|legit)\n",
        "p_x_legit_1000 = []\n",
        "for case in f1000_test_mbf:\n",
        "    p = 1\n",
        "    for i in range(N):\n",
        "        if case[i] == 1:\n",
        "            p *= (word_legit[f1000[i]] + 1) / (legit + 2) # with laplacian smoothing\n",
        "        else:\n",
        "            p *= 1 # different from bernoulli: ignore negative evidence\n",
        "    p_x_legit_1000.append(p)    \n",
        "\n",
        "# compute P(spam)\n",
        "p_spam = spam/(spam+legit)\n",
        "\n",
        "# compute P(legit)\n",
        "p_legit = legit/(spam+legit) \n",
        "\n",
        "# compute P(x)\n",
        "p_x_1000 = []\n",
        "for i in range(len(f1000_test_mbf)):\n",
        "    p = p_spam * p_x_spam_1000[i] + p_legit * p_x_legit_1000[i]\n",
        "    p_x_1000.append(p)\n",
        " \n",
        "#print(len(p_x_spam_1000))\n",
        "#print(len(p_x_1000))"
      ],
      "execution_count": 529,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1dy320NU_tIH"
      },
      "source": [
        "3.2 Classify by computing P(spam|X) and P(legit|X) and compare"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nFtV5PyH_4BQ"
      },
      "source": [
        "f1000_pre = []\n",
        "p_spam_x_1000 = []\n",
        "p_legit_x_1000 = []\n",
        "for i in range(len(f1000_test_mbf)):\n",
        "    psx = p_x_spam_1000[i] * p_spam / p_x_1000[i]\n",
        "    p_spam_x_1000.append(psx)\n",
        "    plx = p_x_legit_1000[i] * p_legit / p_x_1000[i]\n",
        "    p_legit_x_1000.append(plx)\n",
        "    if psx >= plx :\n",
        "        f1000_pre.append(1)\n",
        "    else:\n",
        "        f1000_pre.append(0)"
      ],
      "execution_count": 530,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kMavDZx__zgX"
      },
      "source": [
        "3.3 Report result"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U1gYQGWR_wLH",
        "outputId": "02626cab-6018-43cd-c7fd-3f61b3f3fc2c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "correct = 0;\n",
        "total = len(test_label)\n",
        "for i in range(total):\n",
        "    if test_label[i] == f1000_pre[i]:\n",
        "        correct+=1\n",
        "correct_rate = correct / total\n",
        "print(\"correct rate: \",correct_rate)\n",
        "\n",
        "# spam precision is defined as the fraction of true spam e-mails among all e-mails predicted as spam\n",
        "total_pre_spam = 0\n",
        "true_spam_in_spam = 0\n",
        "for i in range(total):\n",
        "    if f1000_pre[i] == 1:\n",
        "        total_pre_spam += 1\n",
        "        if test_label[i] == 1:\n",
        "            true_spam_in_spam += 1\n",
        "spam_precision_mbf_1000 = true_spam_in_spam / total_pre_spam   \n",
        "print(\"spam precision: \",spam_precision_mbf_1000)\n",
        "\n",
        "# spam recall is defined as fraction of true spam e-mails predicted as spam.\n",
        "pre_spam_in_true = 0\n",
        "total_true_spam = 0\n",
        "for i in range(total):\n",
        "    if test_label[i] == 1:\n",
        "        total_true_spam += 1\n",
        "        if f1000_pre[i] == 1:\n",
        "            pre_spam_in_true += 1\n",
        "        \n",
        "spam_recall_mbf_1000 = pre_spam_in_true / total_true_spam  \n",
        "print(\"spam_recall: \",spam_recall_mbf_1000)"
      ],
      "execution_count": 531,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "correct rate:  0.9896907216494846\n",
            "spam precision:  1.0\n",
            "spam_recall:  0.9387755102040817\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a1YyISUwBa0N"
      },
      "source": [
        "***Adding feature seems helps multinomial NB with binary feature positively***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pv_IcanYBwHa"
      },
      "source": [
        "# Multinomial NB with term frequency (TF) features"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xz6690IYCEib"
      },
      "source": [
        "*Load test data*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZkAUyaNGCR-t"
      },
      "source": [
        "test_label = []  \n",
        "f10_test_mtf = []  # test emails' feature matrix for top 10\n",
        "f100_test_mtf = []  # test emails' feature matrix for top 100\n",
        "f1000_test_mtf = []  # test emails' feature matrix for top 1000\n",
        "emails = [os.path.join(test_path, file_name) for file_name in os.listdir(test_path)]  \n",
        "for email in emails:\n",
        "    # spam: 1, legit: 0\n",
        "    if email.find('spmsg')!=-1:\n",
        "        test_label.append(1)\n",
        "    else:\n",
        "        test_label.append(0)\n",
        "    \n",
        "    with open(email) as m:\n",
        "        temp_f10_tf = []\n",
        "        temp_f100_tf = []\n",
        "        temp_f1000_tf = []\n",
        "\n",
        "        for i, content in enumerate(m):  \n",
        "            if i==2:  # content at 3rd line\n",
        "                words_in_email = set(content.split())\n",
        "                for w in f10:\n",
        "                    if w in words_in_email:\n",
        "                        temp_f10_tf.append(1)\n",
        "                    else:\n",
        "                        temp_f10_tf.append(0)\n",
        "                for w in f100:\n",
        "                    if w in words_in_email:\n",
        "                        temp_f100_tf.append(1)\n",
        "                    else:\n",
        "                        temp_f100_tf.append(0)\n",
        "                for w in f1000:\n",
        "                    if w in words_in_email:\n",
        "                        temp_f1000_tf.append(1)\n",
        "                    else:\n",
        "                        temp_f1000_tf.append(0)\n",
        "\n",
        "        f10_test_mtf.append(temp_f10_tf)\n",
        "        f100_test_mtf.append(temp_f100_tf)\n",
        "        f1000_test_mtf.append(temp_f1000_tf)\n"
      ],
      "execution_count": 532,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hbxPCXR1Ey1X"
      },
      "source": [
        "*For Term Frequency we need new dictionary for words*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cTgLFwMiE5pU",
        "outputId": "311b79a8-30e8-4d4c-f17e-c752e983839a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "# occurence\n",
        "word_occ_spam = {}\n",
        "word_occ_legit = {}\n",
        "for word in dist_words:\n",
        "    word_occ_spam[word] = 0\n",
        "    word_occ_legit[word] = 0\n",
        "\n",
        "for path in paths:\n",
        "    if(path[-2:] == '10'):  \n",
        "        continue\n",
        "    files = [os.path.join(path, f) for f in os.listdir(path)]  \n",
        "    for email in files:\n",
        "        if(email.find('spmsg') != -1):  \n",
        "            is_spam = True\n",
        "        else:\n",
        "            is_spam = False\n",
        "        # dist_set = set() # there could be repeated word, we only need  occurance, use set\n",
        "        with open(email) as m:\n",
        "            for i, content in enumerate(m):  \n",
        "                if(i == 2):  \n",
        "                    words = content.split()\n",
        "                    for word in words:\n",
        "                        if(word.isalpha() == False): # skip symbols\n",
        "                            continue\n",
        "                        else:\n",
        "                            if(is_spam == True):\n",
        "                                word_occ_spam[word] += 1\n",
        "                            else:\n",
        "                                word_occ_legit[word] += 1\n",
        "\n",
        "# total #occurence of word in spam\n",
        "total_occ_spam = 0\n",
        "total_occ_legit = 0\n",
        "for i in word_occ_spam.values():\n",
        "    total_occ_spam += i\n",
        "for i in word_occ_legit.values():\n",
        "    total_occ_legit += i\n",
        "print(f'total words\\' occurence in spam is {total_occ_spam}, total occurence in legit is {total_occ_legit}')    "
      ],
      "execution_count": 533,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total words' occurence in spam is 126257, total occurence in legit is 552314\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RVOqlpZmxGMR"
      },
      "source": [
        "**1. Top 10 feature**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pJjjLJhTxJxp"
      },
      "source": [
        "N = 10"
      ],
      "execution_count": 534,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ll-51BjDxK0S"
      },
      "source": [
        "1.1 compute probability"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y2OxjYhXB7AL"
      },
      "source": [
        "*In TF computation, it requires a lot in precision so we need more decimal: import decimal library*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pKK2h_ZsxNKx"
      },
      "source": [
        "# In TF computation, it requires a lot in precision so we need more decimal\n",
        "from decimal import *\n",
        "getcontext().prec = 32\n",
        "# M = #distinct_term\n",
        "M = len(dist_words)\n",
        "# compute P(x|spam)\n",
        "p_x_spam_10 = []\n",
        "for case in f10_test_mtf:\n",
        "    p = 1\n",
        "    for i in range(N):\n",
        "        if case[i] == 1:\n",
        "            p *= Decimal(word_occ_spam[f10[i]] + 1) / Decimal(total_occ_spam + M) # with laplacian smoothing\n",
        "            # if p == 0 : \n",
        "            #     print(word_occ_spam[f10[i]] + 1, \" \", total_occ_spam + M)\n",
        "        else:\n",
        "            p *= 1 # different from bernoulli: ignore negative evidence \n",
        "    p_x_spam_10.append(p)    \n",
        "\n",
        "# compute P(x|legit)\n",
        "p_x_legit_10 = []\n",
        "for case in f10_test_mtf:\n",
        "    p = 1\n",
        "    for i in range(N):\n",
        "        if case[i] == 1:\n",
        "            p *= Decimal(word_occ_legit[f10[i]] + 1) / Decimal(total_occ_legit + M) # with laplacian smoothing\n",
        "        else:\n",
        "            p *= 1 # different from bernoulli: ignore negative evidence\n",
        "    p_x_legit_10.append(p)    \n",
        "\n",
        "# compute P(spam)\n",
        "p_spam = Decimal(spam)/Decimal((spam+legit))\n",
        "\n",
        "# compute P(legit)\n",
        "p_legit = Decimal(legit)/Decimal((spam+legit)) \n",
        "\n",
        "# compute P(x)\n",
        "p_x_10 = []\n",
        "for i in range(len(f10_test_mtf)):\n",
        "    p = p_spam * p_x_spam_10[i] + p_legit * p_x_legit_10[i]\n",
        "    # if p == 0:\n",
        "    #     print(p_spam, \" \",p_x_spam_10[i],\" \", p_legit,\" \", p_x_legit_10[i])\n",
        "    p_x_10.append(p)\n",
        " \n",
        "#print(len(p_x_spam_10))\n",
        "#print(len(p_x_10))"
      ],
      "execution_count": 535,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2YNXhPJ0xovp"
      },
      "source": [
        "1.2 Classify"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VXsgmNBOxunq",
        "outputId": "aeae5b3d-1827-4519-9248-0a4cdbd6a618",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "f10_pre = []\n",
        "p_spam_x_10 = []\n",
        "p_legit_x_10 = []\n",
        "for i in range(len(f10_test_mbf)):\n",
        "    psx = p_x_spam_10[i] * p_spam / p_x_10[i]\n",
        "    p_spam_x_10.append(psx)\n",
        "    plx = p_x_legit_10[i] * p_legit / p_x_10[i]\n",
        "    p_legit_x_10.append(plx)\n",
        "    if psx >= plx :\n",
        "        f10_pre.append(1)\n",
        "    else:\n",
        "        f10_pre.append(0)\n",
        "\n",
        "print(\"samples of P(X|spam) with Decimal: \")\n",
        "print(p_spam_x_10[:10])"
      ],
      "execution_count": 536,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "samples of P(X|spam) with Decimal: \n",
            "[Decimal('0.99813182451384322042671374197205'), Decimal('0.166026133743274404304381245196'), Decimal('0.0000022034784718669146972481962397807'), Decimal('3.4907685249250161423576733648076E-7'), Decimal('3.4907685249250161423576733648076E-7'), Decimal('0.00028888462741023435198687055770385'), Decimal('5.7340307292691391621873985692292E-8'), Decimal('0.000047464415279492994695890697850526'), Decimal('5.7340307292691391621873985692292E-8'), Decimal('0.00060745961945622674572360319748163')]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mMxK8XDXxq82"
      },
      "source": [
        "1.3 Report result"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-C7Ths5ux7wj",
        "outputId": "c0167721-e746-4f8b-ef54-b7228119de10",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "correct = 0;\n",
        "total = len(test_label)\n",
        "for i in range(total):\n",
        "    if test_label[i] == f10_pre[i]:\n",
        "        correct+=1\n",
        "correct_rate = correct / total\n",
        "print(\"correct rate: \",correct_rate)\n",
        "\n",
        "# spam precision is defined as the fraction of true spam e-mails among all e-mails predicted as spam\n",
        "total_pre_spam = 0\n",
        "true_spam_in_spam = 0\n",
        "for i in range(total):\n",
        "    if f10_pre[i] == 1:\n",
        "        total_pre_spam += 1\n",
        "        if test_label[i] == 1:\n",
        "            true_spam_in_spam += 1\n",
        "spam_precision_mtf_10 = true_spam_in_spam / total_pre_spam   \n",
        "print(\"spam precision: \",spam_precision_mtf_10)\n",
        "\n",
        "# spam recall is defined as fraction of true spam e-mails predicted as spam.\n",
        "pre_spam_in_true = 0\n",
        "total_true_spam = 0\n",
        "for i in range(total):\n",
        "    if test_label[i] == 1:\n",
        "        total_true_spam += 1\n",
        "        if f10_pre[i] == 1:\n",
        "            pre_spam_in_true += 1\n",
        "        \n",
        "spam_recall_mtf_10 = pre_spam_in_true / total_true_spam  \n",
        "print(\"spam_recall: \",spam_recall_mtf_10)"
      ],
      "execution_count": 537,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "correct rate:  0.9553264604810997\n",
            "spam precision:  0.8333333333333334\n",
            "spam_recall:  0.9183673469387755\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZweXHCyusHfU"
      },
      "source": [
        "**2. Top 100 feature**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nXE8UUnXsKCH"
      },
      "source": [
        "N = 100"
      ],
      "execution_count": 538,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5oMQeUdksLhg"
      },
      "source": [
        "2.1 Compute probability"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L2a_YvK_sOpj"
      },
      "source": [
        "# In TF computation, it requires a lot in precision so we need more decimal\n",
        "from decimal import *\n",
        "getcontext().prec = 32\n",
        "# M = #distinct_term\n",
        "M = len(dist_words)\n",
        "# compute P(x|spam)\n",
        "p_x_spam_100 = []\n",
        "for case in f100_test_mtf:\n",
        "    p = 1\n",
        "    for i in range(N):\n",
        "        if case[i] == 1:\n",
        "            p *= Decimal(word_occ_spam[f100[i]] + 1) / Decimal(total_occ_spam + M) # with laplacian smoothing\n",
        "            # if p == 0 : \n",
        "            #     print(word_occ_spam[f100[i]] + 1, \" \", total_occ_spam + M)\n",
        "        else:\n",
        "            p *= 1 # different from bernoulli: ignore negative evidence \n",
        "    p_x_spam_100.append(p)    \n",
        "\n",
        "# compute P(x|legit)\n",
        "p_x_legit_100 = []\n",
        "for case in f100_test_mtf:\n",
        "    p = 1\n",
        "    for i in range(N):\n",
        "        if case[i] == 1:\n",
        "            p *= Decimal(word_occ_legit[f100[i]] + 1) / Decimal(total_occ_legit + M) # with laplacian smoothing\n",
        "        else:\n",
        "            p *= 1 # different from bernoulli: ignore negative evidence\n",
        "    p_x_legit_100.append(p)    \n",
        "\n",
        "# compute P(spam)\n",
        "p_spam = Decimal(spam)/Decimal((spam+legit))\n",
        "\n",
        "# compute P(legit)\n",
        "p_legit = Decimal(legit)/Decimal((spam+legit)) \n",
        "\n",
        "# compute P(x)\n",
        "p_x_100 = []\n",
        "for i in range(len(f100_test_mtf)):\n",
        "    p = p_spam * p_x_spam_100[i] + p_legit * p_x_legit_100[i]\n",
        "    # if p == 0:\n",
        "    #     print(p_spam, \" \",p_x_spam_100[i],\" \", p_legit,\" \", p_x_legit_100[i])\n",
        "    p_x_100.append(p)\n",
        " \n",
        "#print(len(p_x_spam_100))\n",
        "#print(len(p_x_100))"
      ],
      "execution_count": 539,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C1C6AfQDsnW7"
      },
      "source": [
        "2.2 Classify"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zlAClYN3sqO4",
        "outputId": "78cb4928-daff-4f7e-ecd3-845b49a0a952",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "f100_pre = []\n",
        "p_spam_x_100 = []\n",
        "p_legit_x_100 = []\n",
        "for i in range(len(f100_test_mbf)):\n",
        "    psx = p_x_spam_100[i] * p_spam / p_x_100[i]\n",
        "    p_spam_x_100.append(psx)\n",
        "    plx = p_x_legit_100[i] * p_legit / p_x_100[i]\n",
        "    p_legit_x_100.append(plx)\n",
        "    if psx >= plx :\n",
        "        f100_pre.append(1)\n",
        "    else:\n",
        "        f100_pre.append(0)\n",
        "\n",
        "print(\"samples of P(X|spam) with Decimal: \")\n",
        "print(p_spam_x_100[:10])"
      ],
      "execution_count": 540,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "samples of P(X|spam) with Decimal: \n",
            "[Decimal('0.99999999999999998337166666657676'), Decimal('8.7667726792794999330849661998533E-12'), Decimal('4.7808810015814275018609484432725E-15'), Decimal('2.4178519897705639368102547623079E-11'), Decimal('1.2003124232990503545616438244857E-17'), Decimal('5.0123643502595835034544050824268E-20'), Decimal('2.6141063245340595174982451624102E-26'), Decimal('2.8830215514908281028370282449559E-23'), Decimal('1.9001432391592828242709248506245E-16'), Decimal('2.6144283445225336417743383127829E-18')]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eyBO5GyIsypu"
      },
      "source": [
        "2.3 Report result"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mgk32uw8s2HA",
        "outputId": "c01d01ad-09f1-4d8a-e562-ffd7c5d7f3a4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "correct = 0;\n",
        "total = len(test_label)\n",
        "for i in range(total):\n",
        "    if test_label[i] == f100_pre[i]:\n",
        "        correct+=1\n",
        "correct_rate = correct / total\n",
        "print(\"correct rate: \",correct_rate)\n",
        "\n",
        "# spam precision is defined as the fraction of true spam e-mails among all e-mails predicted as spam\n",
        "total_pre_spam = 0\n",
        "true_spam_in_spam = 0\n",
        "for i in range(total):\n",
        "    if f100_pre[i] == 1:\n",
        "        total_pre_spam += 1\n",
        "        if test_label[i] == 1:\n",
        "            true_spam_in_spam += 1\n",
        "spam_precision_mtf_100 = true_spam_in_spam / total_pre_spam   \n",
        "print(\"spam precision: \",spam_precision_mtf_100)\n",
        "\n",
        "# spam recall is defined as fraction of true spam e-mails predicted as spam.\n",
        "pre_spam_in_true = 0\n",
        "total_true_spam = 0\n",
        "for i in range(total):\n",
        "    if test_label[i] == 1:\n",
        "        total_true_spam += 1\n",
        "        if f100_pre[i] == 1:\n",
        "            pre_spam_in_true += 1\n",
        "        \n",
        "spam_recall_mtf_100 = pre_spam_in_true / total_true_spam  \n",
        "print(\"spam_recall: \",spam_recall_mtf_100)"
      ],
      "execution_count": 541,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "correct rate:  0.9862542955326461\n",
            "spam precision:  0.9591836734693877\n",
            "spam_recall:  0.9591836734693877\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-1tM0BI0CuUi"
      },
      "source": [
        "**3. Top 1000 feature**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vsaBaNrUCxlj"
      },
      "source": [
        "N = 1000"
      ],
      "execution_count": 542,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PNCO4l-wCzcc"
      },
      "source": [
        "3.1 Compute probability"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Is9N0YfiC1sE"
      },
      "source": [
        "# In TF computation, it requires a lot in precision so we need more decimal\n",
        "from decimal import *\n",
        "getcontext().prec = 32\n",
        "# M = #distinct_term\n",
        "M = len(dist_words)\n",
        "# compute P(x|spam)\n",
        "p_x_spam_1000 = []\n",
        "for case in f1000_test_mtf:\n",
        "    p = 1\n",
        "    for i in range(N):\n",
        "        if case[i] == 1:\n",
        "            p *= Decimal(word_occ_spam[f1000[i]] + 1) / Decimal(total_occ_spam + M) # with laplacian smoothing\n",
        "            # if p == 0 : \n",
        "            #     print(word_occ_spam[f1000[i]] + 1, \" \", total_occ_spam + M)\n",
        "        else:\n",
        "            p *= 1 # different from bernoulli: ignore negative evidence \n",
        "    p_x_spam_1000.append(p)    \n",
        "\n",
        "# compute P(x|legit)\n",
        "p_x_legit_1000 = []\n",
        "for case in f1000_test_mtf:\n",
        "    p = 1\n",
        "    for i in range(N):\n",
        "        if case[i] == 1:\n",
        "            p *= Decimal(word_occ_legit[f1000[i]] + 1) / Decimal(total_occ_legit + M) # with laplacian smoothing\n",
        "        else:\n",
        "            p *= 1 # different from bernoulli: ignore negative evidence\n",
        "    p_x_legit_1000.append(p)    \n",
        "\n",
        "# compute P(spam)\n",
        "p_spam = Decimal(spam)/Decimal((spam+legit))\n",
        "\n",
        "# compute P(legit)\n",
        "p_legit = Decimal(legit)/Decimal((spam+legit)) \n",
        "\n",
        "# compute P(x)\n",
        "p_x_1000 = []\n",
        "for i in range(len(f1000_test_mtf)):\n",
        "    p = p_spam * p_x_spam_1000[i] + p_legit * p_x_legit_1000[i]\n",
        "    # if p == 0:\n",
        "    #     print(p_spam, \" \",p_x_spam_1000[i],\" \", p_legit,\" \", p_x_legit_1000[i])\n",
        "    p_x_1000.append(p)\n",
        " \n",
        "#print(len(p_x_spam_1000))\n",
        "#print(len(p_x_1000))"
      ],
      "execution_count": 543,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kivb95jvKyN6"
      },
      "source": [
        "3.2 Classify"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-7r49V7iK3vV",
        "outputId": "31280ed9-8944-468a-ccde-10022e5c5327",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "f1000_pre = []\n",
        "p_spam_x_1000 = []\n",
        "p_legit_x_1000 = []\n",
        "for i in range(len(f1000_test_mbf)):\n",
        "    psx = p_x_spam_1000[i] * p_spam / p_x_1000[i]\n",
        "    p_spam_x_1000.append(psx)\n",
        "    plx = p_x_legit_1000[i] * p_legit / p_x_1000[i]\n",
        "    p_legit_x_1000.append(plx)\n",
        "    if psx >= plx :\n",
        "        f1000_pre.append(1)\n",
        "    else:\n",
        "        f1000_pre.append(0)\n",
        "\n",
        "print(\"samples of P(X|spam) with Decimal: \")\n",
        "print(p_spam_x_1000[:10])"
      ],
      "execution_count": 544,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "samples of P(X|spam) with Decimal: \n",
            "[Decimal('1'), Decimal('2.1379484351764377091582505756035E-33'), Decimal('2.3704402227890955375887136402456E-39'), Decimal('4.7433400474497834382595792823822E-46'), Decimal('2.6854239423586455534220495287374E-67'), Decimal('1.6340586087808201789776181084828E-94'), Decimal('3.1013995372555734938318883288304E-66'), Decimal('1.2347449703631891006733487498684E-85'), Decimal('6.1823061090089771542762569055904E-37'), Decimal('2.2495019925776210841146498096943E-51')]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8wM5FwIPK7fk"
      },
      "source": [
        "3.3 Report"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PtNYXDrJK-ZE",
        "outputId": "2779bb32-a1cc-4357-eec4-338f63b5edca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "correct = 0;\n",
        "total = len(test_label)\n",
        "for i in range(total):\n",
        "    if test_label[i] == f1000_pre[i]:\n",
        "        correct+=1\n",
        "correct_rate = correct / total\n",
        "print(\"correct rate: \",correct_rate)\n",
        "\n",
        "# spam precision is defined as the fraction of true spam e-mails among all e-mails predicted as spam\n",
        "total_pre_spam = 0\n",
        "true_spam_in_spam = 0\n",
        "for i in range(total):\n",
        "    if f1000_pre[i] == 1:\n",
        "        total_pre_spam += 1\n",
        "        if test_label[i] == 1:\n",
        "            true_spam_in_spam += 1\n",
        "spam_precision_mtf_1000 = true_spam_in_spam / total_pre_spam   \n",
        "print(\"spam precision: \",spam_precision_mtf_1000)\n",
        "\n",
        "# spam recall is defined as fraction of true spam e-mails predicted as spam.\n",
        "pre_spam_in_true = 0\n",
        "total_true_spam = 0\n",
        "for i in range(total):\n",
        "    if test_label[i] == 1:\n",
        "        total_true_spam += 1\n",
        "        if f1000_pre[i] == 1:\n",
        "            pre_spam_in_true += 1\n",
        "        \n",
        "spam_recall_mtf_1000 = pre_spam_in_true / total_true_spam  \n",
        "print(\"spam_recall: \",spam_recall_mtf_1000)"
      ],
      "execution_count": 545,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "correct rate:  0.9896907216494846\n",
            "spam precision:  1.0\n",
            "spam_recall:  0.9387755102040817\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qWMHUHoqDLLS"
      },
      "source": [
        "# Part2 report: spam precision and spam recall of combinations of NB filters and top-N feature"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "761Rb4QFDmJP",
        "outputId": "72f8b6c9-2442-4790-f230-d2bef633a4de",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 174
        }
      },
      "source": [
        "print(f\"Bernoulli NB with binary feature and top-10: precesion = {spam_precision_bbf_10}, recall = {spam_recall_bbf_10}\")\n",
        "print(f\"Bernoulli NB with binary feature and top-100: precesion = {spam_precision_bbf_100}, recall = {spam_recall_bbf_100}\")\n",
        "print(f\"Bernoulli NB with binary feature and top-1000: precesion = {spam_precision_bbf_1000}, recall = {spam_recall_bbf_1000}\")\n",
        "print(f\"Multinomial NB with binary feature and top-10: precesion = {spam_precision_mbf_10}, recall = {spam_recall_mbf_10}\")\n",
        "print(f\"Multinomial NB with binary feature and top-100: precesion = {spam_precision_mbf_100}, recall = {spam_recall_mbf_100}\")\n",
        "print(f\"Multinomial NB with binary feature and top-1000: precesion = {spam_precision_mbf_1000}, recall = {spam_recall_mbf_1000}\")\n",
        "print(f\"Multinomial NB with term frequency and top-10: precesion = {spam_precision_mtf_10}, recall = {spam_recall_mtf_10}\")\n",
        "print(f\"Multinomial NB with term frequency and top-100: precesion = {spam_precision_mtf_100}, recall = {spam_recall_mtf_100}\")\n",
        "print(f\"Multinomial NB with term frequency and top-1000: precesion = {spam_precision_mtf_1000}, recall = {spam_recall_mtf_1000}\")"
      ],
      "execution_count": 546,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Bernoulli NB with binary feature and top-10: precesion = 0.8888888888888888, recall = 0.8163265306122449\n",
            "Bernoulli NB with binary feature and top-100: precesion = 1.0, recall = 0.673469387755102\n",
            "Bernoulli NB with binary feature and top-1000: precesion = 1.0, recall = 0.6122448979591837\n",
            "Multinomial NB with binary feature and top-10: precesion = 0.8695652173913043, recall = 0.8163265306122449\n",
            "Multinomial NB with binary feature and top-100: precesion = 0.9038461538461539, recall = 0.9591836734693877\n",
            "Multinomial NB with binary feature and top-1000: precesion = 1.0, recall = 0.9387755102040817\n",
            "Multinomial NB with term frequency and top-10: precesion = 0.8333333333333334, recall = 0.9183673469387755\n",
            "Multinomial NB with term frequency and top-100: precesion = 0.9591836734693877, recall = 0.9591836734693877\n",
            "Multinomial NB with term frequency and top-1000: precesion = 1.0, recall = 0.9387755102040817\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U3TSwH4h8zYU"
      },
      "source": [
        "# SVM based filter"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V_fiAwqvA28y"
      },
      "source": [
        "load data, generate top-N feature matrix with IG"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aoS7qJwZ_q5f"
      },
      "source": [
        "train_path = './lingspam_public/lemm_stop'  # parent directory of dataset we use\n",
        "paths = [os.path.join(train_path, folders) for folders in os.listdir(train_path)]  \n",
        "all_words = [] \n",
        "\n",
        "train_data = [] # all feature\n",
        "train_data_10 = []\n",
        "train_data_100 = []\n",
        "train_data_1000 = []\n",
        "train_label = []\n",
        "\n",
        "test_data = [] # all feature\n",
        "test_data_10 = []\n",
        "test_data_100 = []\n",
        "test_data_1000 = []\n",
        "test_label = []\n",
        "\n",
        "\n",
        "\n",
        "for path in paths:\n",
        "    files = [os.path.join(path, f) for f in os.listdir(path)]  # get file names of this part and generate path to files\n",
        "    for email in files:\n",
        "        if email.find('spmsg') != -1 : #check filenames to check if it is spam \n",
        "            if path[-2:] == '10' : # if it is test data\n",
        "                test_label.append(1)\n",
        "            else:\n",
        "                train_label.append(1)\n",
        "        else:\n",
        "            if path[-2:] == '10' :\n",
        "                test_label.append(0)\n",
        "            else:\n",
        "                train_label.append(0)\n",
        "        \n",
        "        with open(email) as m:\n",
        "            for i, content in enumerate(m):  # i: line number , content: content of each line\n",
        "                if(i == 2):  # open txt and find content is in the 3rd line\n",
        "                    words_in_email = set(content.split())\n",
        "                    temp_train_10 = []\n",
        "                    temp_train_100 = []\n",
        "                    temp_train_1000 = []\n",
        "                    temp_test_10 = []\n",
        "                    temp_test_100 = []\n",
        "                    temp_test_1000 = []\n",
        "\n",
        "                    temp_train = []\n",
        "                    temp_test = []\n",
        "                    for w in dist_words:\n",
        "                        if w in words_in_email:\n",
        "                            if path[-2:] == '10' :\n",
        "                                temp_test.append(1)\n",
        "                            else:\n",
        "                                temp_train.append(1)\n",
        "                        else:\n",
        "                            if path[-2:] == '10' :\n",
        "                                temp_test.append(0)\n",
        "                            else:\n",
        "                                temp_train.append(0)\n",
        "                    for w in f10:\n",
        "                        if w in words_in_email:\n",
        "                            if path[-2:] == '10' :\n",
        "                                temp_test_10.append(1)\n",
        "                            else:\n",
        "                                temp_train_10.append(1)\n",
        "                        else:\n",
        "                            if path[-2:] == '10' :\n",
        "                                temp_test_10.append(0)\n",
        "                            else:\n",
        "                                temp_train_10.append(0)\n",
        "                    for w in f100:\n",
        "                        if w in words_in_email:\n",
        "                            if path[-2:] == '10' :\n",
        "                                temp_test_100.append(1)\n",
        "                            else:\n",
        "                                temp_train_100.append(1)\n",
        "                        else:\n",
        "                            if path[-2:] == '10' :\n",
        "                                temp_test_100.append(0)\n",
        "                            else:\n",
        "                                temp_train_100.append(0)\n",
        "                    for w in f1000:\n",
        "                        if w in words_in_email:\n",
        "                            if path[-2:] == '10' :\n",
        "                                temp_test_1000.append(1)\n",
        "                            else:\n",
        "                                temp_train_1000.append(1)\n",
        "                        else:\n",
        "                            if path[-2:] == '10' :\n",
        "                                temp_test_1000.append(0)\n",
        "                            else:\n",
        "                                temp_train_1000.append(0)\n",
        "\n",
        "        if path[-2:] == '10':\n",
        "            test_data.append(np.array(temp_test))\n",
        "            test_data_10.append(np.array(temp_test_10))\n",
        "            test_data_100.append(np.array(temp_test_100))\n",
        "            test_data_1000.append(np.array(temp_test_1000))\n",
        "        else :\n",
        "            train_data.append(np.array(temp_train))\n",
        "            train_data_10.append(np.array(temp_train_10))\n",
        "            train_data_100.append(np.array(temp_train_100))\n",
        "            train_data_1000.append(np.array(temp_train_1000))\n"
      ],
      "execution_count": 547,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F1kFfzQ1XjMV"
      },
      "source": [
        "*Memo for an exception : when I try to fit for SVM, it says \"setting an array element with a sequence\" which indicates my matrix is not a generalized \"rectangular\", then I found I mistakenly wrote temp_train_10.append() in a top-1000 situation(part10).*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JIjKmoxzyA74"
      },
      "source": [
        "**ALL feature**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B7W--yMH83qu"
      },
      "source": [
        "*Memo: Be carefull with strength of regularization,  make it soft because what I have is 0-1 feature!*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UL9BntD7yEXn",
        "outputId": "82f874dc-56e7-4bdc-cb05-3b14d9e58a30",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "from sklearn import svm\n",
        "svm_ = svm.SVC(kernel = 'rbf',C=1000,probability=False) # because it is 0-1 feature, no need for strength on regularization\n",
        "%time svm_.fit(train_data,train_label)"
      ],
      "execution_count": 548,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 2min 30s, sys: 91.1 ms, total: 2min 30s\n",
            "Wall time: 2min 30s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SVC(C=1000, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
              "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n",
              "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
              "    tol=0.001, verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 548
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bo8E161ZyI13",
        "outputId": "62e3fc98-0287-4f8b-fd82-e2f92a380cba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "pre_svm = svm_.predict(test_data)\n",
        "print(pre_svm)"
      ],
      "execution_count": 549,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
            " 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
            " 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
            " 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 1 0 0 1 0 0 0 1 0 0 0 0\n",
            " 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0\n",
            " 1 1 0 0 0 1 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 1 0 0 0 1 0 0 1 0 0 0 0 1 0\n",
            " 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 1 0 0 1 1 1\n",
            " 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 1 1 0 0 0 0 0 0 0 0 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J7UtkBcTyOss",
        "outputId": "ee6df8ec-d3c3-483a-d8ef-501288b848c4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "total = len(test_label)\n",
        "# correct rate\n",
        "score = svm_.score(test_data, test_label)\n",
        "print(\"correct rate: \",score)\n",
        "\n",
        "# spam precision is defined as the fraction of true spam e-mails among all e-mails predicted as spam\n",
        "total_pre_spam = 0\n",
        "true_spam_in_spam = 0\n",
        "for i in range(total):\n",
        "    if pre_svm[i] == 1:\n",
        "        total_pre_spam += 1\n",
        "        if test_label[i] == 1:\n",
        "            true_spam_in_spam += 1\n",
        "spam_precision_svm_af = true_spam_in_spam / (total_pre_spam) \n",
        "print(\"spam precision: \",spam_precision_svm_af)\n",
        "\n",
        "# spam recall is defined as fraction of true spam e-mails predicted as spam.\n",
        "pre_spam_in_true = 0\n",
        "total_true_spam = 0\n",
        "for i in range(total):\n",
        "    if test_label[i] == 1:\n",
        "        total_true_spam += 1\n",
        "        if pre_svm[i] == 1:\n",
        "            pre_spam_in_true += 1\n",
        "        \n",
        "spam_recall_svm_af = pre_spam_in_true / total_true_spam  \n",
        "print(\"spam_recall: \",spam_recall_svm_af)"
      ],
      "execution_count": 550,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "correct rate:  0.9828178694158075\n",
            "spam precision:  1.0\n",
            "spam_recall:  0.8979591836734694\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uf0RKaVHopb6"
      },
      "source": [
        "**1. Top 10 feature**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2vk9XZKY9X7Y",
        "outputId": "7eb87dcb-16b7-4bcd-9303-fe18211b8037",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "from sklearn import svm\n",
        "#svm_10 = svm.SVC(kernel = 'linear',C=1000,probability=False)\n",
        "svm_10 = svm.SVC(kernel = 'rbf',C=1000,probability=False)\n",
        "%time svm_10.fit(train_data_10,train_label)"
      ],
      "execution_count": 551,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 40.1 ms, sys: 977 µs, total: 41 ms\n",
            "Wall time: 42.5 ms\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SVC(C=1000, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
              "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n",
              "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
              "    tol=0.001, verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 551
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NjBahG4gndCe",
        "outputId": "4669a976-5281-474c-c1d1-c7f1d4fe2819",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "pre_svm_10 = svm_10.predict(test_data_10)\n",
        "print(pre_svm_10)"
      ],
      "execution_count": 552,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
            " 0 0 0 0 0 1 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
            " 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 0 1 0 0 0 0 0 0 1 0 0 0 0\n",
            " 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 1 0 0 0\n",
            " 1 1 0 0 0 1 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 1 0 0 1 0 0 0 0 1 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 1 1 1\n",
            " 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 1 0 1 1 0 0 0 0 0 0 0 0 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ssgpSBGh-4Ef",
        "outputId": "e4e5904c-383f-4439-9a35-130277f6957f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "total = len(test_label)\n",
        "# correct rate\n",
        "score_10 = svm_10.score(test_data_10, test_label)\n",
        "print(\"correct rate: \",score_10)\n",
        "\n",
        "# spam precision is defined as the fraction of true spam e-mails among all e-mails predicted as spam\n",
        "total_pre_spam = 0\n",
        "true_spam_in_spam = 0\n",
        "for i in range(total):\n",
        "    if pre_svm_10[i] == 1:\n",
        "        total_pre_spam += 1\n",
        "        if test_label[i] == 1:\n",
        "            true_spam_in_spam += 1\n",
        "spam_precision_svm_10 = true_spam_in_spam / (total_pre_spam) \n",
        "print(\"spam precision: \",spam_precision_svm_10)\n",
        "\n",
        "# spam recall is defined as fraction of true spam e-mails predicted as spam.\n",
        "pre_spam_in_true = 0\n",
        "total_true_spam = 0\n",
        "for i in range(total):\n",
        "    if test_label[i] == 1:\n",
        "        total_true_spam += 1\n",
        "        if pre_svm_10[i] == 1:\n",
        "            pre_spam_in_true += 1\n",
        "        \n",
        "spam_recall_svm_10 = pre_spam_in_true / total_true_spam  \n",
        "print(\"spam_recall: \",spam_recall_svm_10)"
      ],
      "execution_count": 553,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "correct rate:  0.9450171821305842\n",
            "spam precision:  0.851063829787234\n",
            "spam_recall:  0.8163265306122449\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CDh5NPWwo0ZP"
      },
      "source": [
        "**2. Top 100 feature**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LzLkRjdaJOWZ",
        "outputId": "3b91314e-b51a-4bbf-ecde-96fd6ff67f8f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "from sklearn import svm\n",
        "#svm_100 = svm.SVC(kernel = 'linear',C=1000,probability=False)\n",
        "svm_100 = svm.SVC(kernel = 'rbf',C=1000,probability=False)\n",
        "%time svm_100.fit(train_data_100,train_label)"
      ],
      "execution_count": 554,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 173 ms, sys: 2.99 ms, total: 176 ms\n",
            "Wall time: 175 ms\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SVC(C=1000, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
              "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n",
              "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
              "    tol=0.001, verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 554
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T56lextMn_RD",
        "outputId": "a649cf62-3ee9-473f-9941-f02e9d668485",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "pre_svm_100 = svm_100.predict(test_data_100)\n",
        "print(pre_svm_100)"
      ],
      "execution_count": 555,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
            " 0 0 0 0 0 1 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
            " 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 1 0 0 0 0 0 0 1 0 0 0 0\n",
            " 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 1 0 0 0\n",
            " 0 1 0 0 0 1 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 1 0 0 0 1 0 0 1 0 0 0 0 1 0\n",
            " 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 1 1 1\n",
            " 0 0 0 0 0 0 0 1 0 0 0 1 0 0 1 0 0 0 0 1 0 1 1 0 0 0 0 0 0 0 0 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ik9pIEYxJQRb",
        "outputId": "b2f2c9a7-798f-4b79-8ae4-5b3a231bbcc9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "total = len(test_label)\n",
        "# correct rate\n",
        "score_100 = svm_100.score(test_data_100, test_label)\n",
        "print(\"correct rate: \",score_100)\n",
        "\n",
        "# spam precision is defined as the fraction of true spam e-mails among all e-mails predicted as spam\n",
        "total_pre_spam = 0\n",
        "true_spam_in_spam = 0\n",
        "for i in range(total):\n",
        "    if pre_svm_100[i] == 1:\n",
        "        total_pre_spam += 1\n",
        "        if test_label[i] == 1:\n",
        "            true_spam_in_spam += 1\n",
        "spam_precision_svm_100 = true_spam_in_spam / (total_pre_spam) \n",
        "print(\"spam precision: \",spam_precision_svm_100)\n",
        "\n",
        "# spam recall is defined as fraction of true spam e-mails predicted as spam.\n",
        "pre_spam_in_true = 0\n",
        "total_true_spam = 0\n",
        "for i in range(total):\n",
        "    if test_label[i] == 1:\n",
        "        total_true_spam += 1\n",
        "        if pre_svm_100[i] == 1:\n",
        "            pre_spam_in_true += 1\n",
        "        \n",
        "spam_recall_svm_100 = pre_spam_in_true / total_true_spam  \n",
        "print(\"spam_recall: \",spam_recall_svm_100)"
      ],
      "execution_count": 556,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "correct rate:  0.9690721649484536\n",
            "spam precision:  0.9545454545454546\n",
            "spam_recall:  0.8571428571428571\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9VCm0VD0o23z"
      },
      "source": [
        "**3. Top 1000 feature**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9yYZg6cPJPEn",
        "outputId": "50fb5a18-eb9d-4843-edea-47c647fe6632",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "from sklearn import svm\n",
        "#svm_1000 = svm.SVC(kernel = 'linear',C=1000,probability=False)\n",
        "svm_1000 = svm.SVC(kernel = 'rbf',C=1000,probability=False)\n",
        "%time svm_1000.fit(train_data_1000,train_label)"
      ],
      "execution_count": 557,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 2.39 s, sys: 4.01 ms, total: 2.39 s\n",
            "Wall time: 2.4 s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SVC(C=1000, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
              "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n",
              "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
              "    tol=0.001, verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 557
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZRFgY2o4odP4",
        "outputId": "6159495f-a865-4443-f45f-0f9752a40bbb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "pre_svm_1000 = svm_1000.predict(test_data_1000)\n",
        "print(pre_svm_1000)"
      ],
      "execution_count": 558,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
            " 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
            " 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
            " 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 1 0 0 1 0 0 0 1 0 0 0 0\n",
            " 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 1 0 0 0\n",
            " 0 1 0 0 0 1 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 1 0 0 0 1 0 0 1 0 0 0 0 1 0\n",
            " 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 1 1 0 0 0 0 0 0 0 0 1 0 0 1 1 1\n",
            " 0 0 0 0 0 0 0 1 0 0 0 1 0 0 1 0 0 0 0 1 0 1 1 0 0 0 0 0 0 0 0 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A0wf3HcCJRQJ",
        "outputId": "74bd86e4-79ec-4bde-d7a1-fe23c2936380",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "total = len(test_label)\n",
        "# correct rate\n",
        "score_1000 = svm_1000.score(test_data_1000, test_label)\n",
        "print(\"correct rate: \",score_1000)\n",
        "\n",
        "# spam precision is defined as the fraction of true spam e-mails among all e-mails predicted as spam\n",
        "total_pre_spam = 0\n",
        "true_spam_in_spam = 0\n",
        "for i in range(total):\n",
        "    if pre_svm_1000[i] == 1:\n",
        "        total_pre_spam += 1\n",
        "        if test_label[i] == 1:\n",
        "            true_spam_in_spam += 1\n",
        "spam_precision_svm_1000 = true_spam_in_spam / (total_pre_spam) \n",
        "print(\"spam precision: \",spam_precision_svm_1000)\n",
        "\n",
        "# spam recall is defined as fraction of true spam e-mails predicted as spam.\n",
        "pre_spam_in_true = 0\n",
        "total_true_spam = 0\n",
        "for i in range(total):\n",
        "    if test_label[i] == 1:\n",
        "        total_true_spam += 1\n",
        "        if pre_svm_1000[i] == 1:\n",
        "            pre_spam_in_true += 1\n",
        "        \n",
        "spam_recall_svm_1000 = pre_spam_in_true / total_true_spam  \n",
        "print(\"spam_recall: \",spam_recall_svm_1000)"
      ],
      "execution_count": 559,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "correct rate:  0.9862542955326461\n",
            "spam precision:  0.9787234042553191\n",
            "spam_recall:  0.9387755102040817\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AioIBrbJGe2x"
      },
      "source": [
        "# Part4 Report: SVM spam precision and spam recall"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6_nY7U_bGqNY"
      },
      "source": [
        "I used SVM with RBF kernel, it perform obviously better on recall than linear kernel. And I set regularization very soft because I am using binary feature, it only has 0 or 1. \n",
        "\n",
        "For features, I used binary word feature, and select them by IG used before, I tried all feature and top-10, top-100, top-1000 from IG.\n",
        "\n",
        "**It results into top-1000 with RBF kernel performs best in general, because its precision and recall rate are both high.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ffeDTAYHqft",
        "outputId": "7bd5bd26-bc63-4d42-c5d6-4b8458dac0a2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "print(f\"RBF kernal with all feature: precision = {spam_precision_svm_af}, recall = {spam_recall_svm_af}\")\n",
        "print(f\"RBF kernal with top-10 feature: precision = {spam_precision_svm_10}, recall = {spam_recall_svm_10}\")\n",
        "print(f\"RBF kernal with top-100 feature: precision = {spam_precision_svm_100}, recall = {spam_recall_svm_100}\")\n",
        "print(f\"RBF kernal with top-1000 feature: precision = {spam_precision_svm_1000}, recall = {spam_recall_svm_1000}\")"
      ],
      "execution_count": 560,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "RBF kernal with all feature: precision = 1.0, recall = 0.8979591836734694\n",
            "RBF kernal with top-10 feature: precision = 0.851063829787234, recall = 0.8163265306122449\n",
            "RBF kernal with top-100 feature: precision = 0.9545454545454546, recall = 0.8571428571428571\n",
            "RBF kernal with top-1000 feature: precision = 0.9787234042553191, recall = 0.9387755102040817\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fPY4ljSEJH6w"
      },
      "source": [
        "Some extra statistics when using linear kernel:\n",
        "\n",
        "linear & top-10: precision = 0.88372, recall = 0.775510\n",
        "\n",
        "linear & top-100: precision = 0.9743, recall = 0.775510\n",
        "\n",
        "linear & top-1000: precision = 1.0, recall = 0.85714"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xCfFp2XdKQX2"
      },
      "source": [
        "# Adversarial Classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0KfE4_AZ8oqi"
      },
      "source": [
        "baseline multinomial NB with binary feature and top-10 feature"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HuK7tc2W-AdD"
      },
      "source": [
        "**1. Before attacker's modification**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EF0qwRSm7hxn"
      },
      "source": [
        "N = 10\n",
        "test_label = []  \n",
        "f10_test_mbf = []  # test emails' feature matrix for top 10\n",
        "\n",
        "emails = [os.path.join(test_path, file_name) for file_name in os.listdir(test_path)]  \n",
        "for email in emails:\n",
        "    # spam: 1, legit: 0\n",
        "    if email.find('spmsg')!=-1:\n",
        "        test_label.append(1)\n",
        "    else:\n",
        "        test_label.append(0)\n",
        "    \n",
        "    with open(email) as m:\n",
        "        temp_f10_bf = []\n",
        "        for i, content in enumerate(m):  \n",
        "            if i==2:  # content at 3rd line\n",
        "                words_in_email = set(content.split())\n",
        "                for w in f10:\n",
        "                    if w in words_in_email:\n",
        "                        temp_f10_bf.append(1)\n",
        "                    else:\n",
        "                        temp_f10_bf.append(0)\n",
        "\n",
        "        f10_test_mbf.append(temp_f10_bf)\n",
        "        \n",
        "# compute P(x|spam)\n",
        "p_x_spam_10 = []\n",
        "for case in f10_test_mbf:\n",
        "    p = 1\n",
        "    for i in range(N):\n",
        "        if case[i] == 1:\n",
        "            p *= (word_spam[f10[i]] + 1) / (spam + 2) \n",
        "        else:\n",
        "            p *= 1 \n",
        "    p_x_spam_10.append(p)    \n",
        "\n",
        "# compute P(x|legit)\n",
        "p_x_legit_10 = []\n",
        "for case in f10_test_mbf:\n",
        "    p = 1\n",
        "    for i in range(N):\n",
        "        if case[i] == 1:\n",
        "            p *= (word_legit[f10[i]] + 1) / (legit + 2) \n",
        "        else:\n",
        "            p *= 1 \n",
        "    p_x_legit_10.append(p)    \n",
        "\n",
        "# compute P(spam)\n",
        "p_spam = spam/(spam+legit)\n",
        "\n",
        "# compute P(legit)\n",
        "p_legit = legit/(spam+legit) \n",
        "\n",
        "# compute P(x)\n",
        "p_x_10 = []\n",
        "for i in range(len(f10_test_mbf)):\n",
        "    p = p_spam * p_x_spam_10[i] + p_legit * p_x_legit_10[i]\n",
        "    p_x_10.append(p)\n",
        " \n",
        "#print(len(p_x_spam_10))\n",
        "#print(len(p_x_10))\n",
        "\n",
        "f10_pre = []\n",
        "p_spam_x_10 = []\n",
        "p_legit_x_10 = []\n",
        "for i in range(len(f10_test_mbf)):\n",
        "    psx = p_x_spam_10[i] * p_spam / p_x_10[i]\n",
        "    p_spam_x_10.append(psx)\n",
        "    plx = p_x_legit_10[i] * p_legit / p_x_10[i]\n",
        "    p_legit_x_10.append(plx)\n",
        "    if psx >= plx :\n",
        "        f10_pre.append(1)\n",
        "    else:\n",
        "        f10_pre.append(0)"
      ],
      "execution_count": 561,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xJzNv89U-eBd",
        "outputId": "3dd228b2-632e-49a2-ebde-9de49807fa02",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# false negative\n",
        "fn_before = 0\n",
        "true_positive = 0\n",
        "for i in range(total):\n",
        "    if test_label[i] == 1 and f10_pre[i] == 1 :\n",
        "        true_positive +=1\n",
        "    if test_label[i] == 1 and f10_pre[i] == 0:\n",
        "        fn_before+= 1\n",
        "        \n",
        "fnr_before = n_fn_before / (true_positive + n_fn_before)  \n",
        "print(\"Flase negative rate before attacker's modification: \",fnr_before) "
      ],
      "execution_count": 562,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Flase negative rate before attacker's modification:  0.1836734693877551\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yimLEwFbAQgV"
      },
      "source": [
        "**2. After attacker's modification**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H0SZSYbvWyCV"
      },
      "source": [
        "Compute P(Xi=xi|C=c)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "woVP6pDFWvVA"
      },
      "source": [
        "# compute P(x|spam)\n",
        "\n",
        "p_1_spam_10 = []\n",
        "p_0_spam_10 = []\n",
        "\n",
        "for i in range(N):\n",
        "    # 1_spam\n",
        "    p = (word_spam[f10[i]] + 1) / (spam + 2) # with laplacian smoothing\n",
        "    p_1_spam_10.append(p)\n",
        "    # 0_spam\n",
        "    p = 1 - (word_spam[f10[i]] + 1) / (spam + 2)   \n",
        "    p_0_spam_10.append(p) \n",
        "\n",
        "# compute P(x|legit)\n",
        "p_1_legit_10 = []\n",
        "p_0_legit_10 = []\n",
        "p = 1\n",
        "for i in range(N):\n",
        "    # 1_spam\n",
        "    p = (word_legit[f10[i]] + 1) / (legit + 2) # with laplacian smoothing\n",
        "    p_1_legit_10.append(p)\n",
        "    # 0_spam\n",
        "    p = 1 - (word_legit[f10[i]] + 1) / (legit + 2)\n",
        "    p_0_legit_10.append(p)  "
      ],
      "execution_count": 563,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NBKx49lpWv5n"
      },
      "source": [
        "Compute desired reduction log( P(spam | x) / P(legit | x) ) =  log( P(x | spam) / P(x | legit) ) + log(P(spam)/P(legit))"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E7D46KICWuq-",
        "outputId": "c5c75082-694d-491d-eb89-3992ff90661e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "desired_delta = []\n",
        "for case in f10_test_mbf:\n",
        "    p = 1\n",
        "    for i in range(N):\n",
        "        if case[i] == 1:\n",
        "            p *= p_1_spam_10[i] / p_1_legit_10[i]\n",
        "        else:\n",
        "            p *= p_0_spam_10[i] / p_0_legit_10[i]\n",
        "    d = np.log2(p) + np.log2(spam/legit)\n",
        "    desired_delta.append(d)\n",
        "\n",
        "print(\"desired delta:\",desired_delta[5:15])\n",
        "print(\"corresponding label:\",test_label[5:15])"
      ],
      "execution_count": 564,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "desired delta: [-12.546866882101583, -24.16676583757637, -15.405885725154178, -24.16676583757637, -10.254593464194329, 5.0048781098057695, -14.629465573740717, -24.16676583757637, -19.123452183326485, -15.405885725154178]\n",
            "corresponding label: [0, 0, 0, 0, 0, 1, 0, 0, 0, 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ypu9FgbJTYcK"
      },
      "source": [
        "compute  delta_LO_ix' = LOc(xi) - LOc(xi') for top-10 features"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5JVF3TnET1PE"
      },
      "source": [
        "LO(xi) = log( P(xi | spam) / P(xi | legit) )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qi857GUkdFVC"
      },
      "source": [
        "As assignment states, the adversary only use **ADD_WORDS** strategy, so I set reduction for term_i to 0 when each email has this term"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OoeoO7FFgkVH"
      },
      "source": [
        "Only consider adding word for reduction of each feature "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YnTah27mggNS"
      },
      "source": [
        "delta_add_word = []\n",
        "for i in range(10):\n",
        "    d = np.log2(p_0_spam_10[i] / p_0_legit_10[i]) - np.log2(p_1_spam_10[i] / p_1_legit_10[i]) # delta_LO_ix' = LOc(xi) - LOc(xi') old - new\n",
        "    d = max(0,d)\n",
        "    delta_add_word.append(d)"
      ],
      "execution_count": 565,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "26rhBYU8h8XY"
      },
      "source": [
        "determine reduction acquired and **sort them** by value, now we can see top-10words in this sorted order"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VO3YQ-mgAUvB",
        "outputId": "f398963f-9a05-484e-e77c-6b76fa08b99e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 227
        }
      },
      "source": [
        "sorted_delta = []\n",
        "for case in f10_test_mbf:\n",
        "    delta_i = {}\n",
        "    for i in range(10):\n",
        "        if case[i] == 1:\n",
        "            delta_i[f10[i]] = 0\n",
        "        else:\n",
        "            delta_i[f10[i]] = delta_add_word[i]\n",
        "    sorted_delta_i = OrderedDict(sorted(delta_i.items(), key=lambda x : x[1], reverse=True))\n",
        "    sorted_delta.append(sorted_delta_i)\n",
        "\n",
        "#print(\"check f_index helper: index of remove\",f_index[\"remove\"])\n",
        "print(\"orgin f10 sequence: \", f10)\n",
        "#print(\"case 0:\", f10_test_mbf[0])\n",
        "print(\"desired delta of case 0: \",desired_delta[0])\n",
        "for (w,d) in sorted_delta[0].items():\n",
        "    print(w,\":\", d)"
      ],
      "execution_count": 566,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "orgin f10 sequence:  ['language', 'remove', 'free', 'linguistic', 'university', 'money', 'click', 'market', 'our', 'business']\n",
            "desired delta of case 0:  7.430667122628313\n",
            "linguistic : 8.760880112422193\n",
            "language : 6.678281420783058\n",
            "university : 5.043313654249885\n",
            "remove : 0\n",
            "free : 0\n",
            "money : 0\n",
            "click : 0\n",
            "market : 0\n",
            "our : 0\n",
            "business : 0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P5K32mXNk3dp"
      },
      "source": [
        "Because adding a term incur an unit cost, we can pick term with larger reduction first (*being greedy*) for minimum cost tring to meet desired reduction! "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JHW6GxE-NuAr"
      },
      "source": [
        "**Start modify**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-fg5dtkFlqkN",
        "outputId": "7883d333-9f6f-4421-ce4a-4f804ae676fb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# feature index helper\n",
        "f_index = {}\n",
        "for i in range(10):\n",
        "    f_index[f10[i]]=i\n",
        "\n",
        "avg_cost = 0\n",
        "test_spam = 0\n",
        "f10_test_mbf_mod = []\n",
        "for i in f10_test_mbf:\n",
        "    f10_test_mbf_mod.append(i.copy())\n",
        "\n",
        "for i in range(len(sorted_delta)):\n",
        "    if test_label[i] == 0: # do not modify legit email\n",
        "        continue\n",
        "    else:\n",
        "        test_spam+=1\n",
        "    d = sorted_delta[i]\n",
        "    sum = 0\n",
        "    for (k,v) in d.items():\n",
        "        if v <= 0: #if value reach 0 in sorted reduction values, can't reach desired reduction, break\n",
        "            break\n",
        "        else: # reduction > 0\n",
        "            f10_test_mbf_mod[i][f_index[k]] = 1 # add word\n",
        "            avg_cost+=1\n",
        "            sum += v\n",
        "            if desired_delta[i] <= sum: # meet desired reduction \n",
        "                break; \n",
        "avg_cost /= test_spam\n",
        "print(\"average cost of attacker: \", avg_cost)                "
      ],
      "execution_count": 567,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "average cost of attacker:  1.469387755102041\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P1MjFX-or8Oc",
        "outputId": "b28661c5-cb71-41ed-f922-eabd2547ae10",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "print(f10)\n",
        "print(\"origin:\",f10_test_mbf[0])\n",
        "print(\"modify:\",f10_test_mbf_mod[0])"
      ],
      "execution_count": 568,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['language', 'remove', 'free', 'linguistic', 'university', 'money', 'click', 'market', 'our', 'business']\n",
            "origin: [0, 0, 1, 0, 0, 0, 0, 0, 1, 1]\n",
            "modify: [0, 0, 1, 1, 0, 0, 0, 0, 1, 1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nvaPcfkiosRP"
      },
      "source": [
        "perform classification after attacker's modification on test data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-xBpso77orm0"
      },
      "source": [
        "# compute P(x|spam)\n",
        "p_x_spam_10 = []\n",
        "for case in f10_test_mbf_mod:\n",
        "    p = 1\n",
        "    for i in range(N):\n",
        "        if case[i] == 1:\n",
        "            p *= (word_spam[f10[i]] + 1) / (spam + 2) # with laplacian smoothing\n",
        "        else:\n",
        "            p *= 1 \n",
        "    p_x_spam_10.append(p)    \n",
        "\n",
        "# compute P(x|legit)\n",
        "p_x_legit_10 = []\n",
        "for case in f10_test_mbf_mod:\n",
        "    p = 1\n",
        "    for i in range(N):\n",
        "        if case[i] == 1:\n",
        "            p *= (word_legit[f10[i]] + 1) / (legit + 2) # with laplacian smoothing\n",
        "        else:\n",
        "            p *= 1 \n",
        "    p_x_legit_10.append(p)    \n",
        "\n",
        "# compute P(x)\n",
        "p_x_10 = []\n",
        "for i in range(len(f10_test_mbf_mod)):\n",
        "    p = p_spam * p_x_spam_10[i] + p_legit * p_x_legit_10[i]\n",
        "    p_x_10.append(p)\n",
        "\n",
        "f10_mod_pre = []\n",
        "p_spam_x_10 = []\n",
        "p_legit_x_10 = []\n",
        "for i in range(len(f10_test_mbf_mod)):\n",
        "    psx = p_x_spam_10[i] * p_spam / p_x_10[i]\n",
        "    p_spam_x_10.append(psx)\n",
        "    plx = p_x_legit_10[i] * p_legit / p_x_10[i]\n",
        "    p_legit_x_10.append(plx)\n",
        "    if psx >= plx :\n",
        "        f10_mod_pre.append(1)\n",
        "    else:\n",
        "        f10_mod_pre.append(0)"
      ],
      "execution_count": 569,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t10HnbOzpInh",
        "outputId": "3d65188d-37d9-4774-a17c-71c89bdcc488",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# false negative\n",
        "fn_after = 0\n",
        "true_positive = 0\n",
        "for i in range(total):\n",
        "    if test_label[i] == 1 and f10_mod_pre[i] == 1 :\n",
        "        true_positive +=1\n",
        "    if test_label[i] == 1 and f10_mod_pre[i] == 0:\n",
        "        fn_after+= 1\n",
        "        \n",
        "fnr_after = fn_after / (true_positive + fn_after)  \n",
        "print(\"Flase negative rate after attacker's modification: \",fnr_after) "
      ],
      "execution_count": 570,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Flase negative rate after attacker's modification:  0.9183673469387755\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kLWkJZvFiXcB"
      },
      "source": [
        "**3. After Update calssifier**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6QwpSAqQllHd"
      },
      "source": [
        "PA{spam|x'}/PA{legit|x'} = PA{x'|spam}*PA{SPAM} / (PA{x'|legit} * PA{legit})"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sd3lW_fbk82O"
      },
      "source": [
        "# # compute PA(x'|spam), x' can be generated by any possible x (ADD WORDS)so it is sum of P(x|spam)\n",
        "# p_x_spam_10 = []\n",
        "# for CASE in f10_test_mbf_mod: # facing attack\n",
        "#     sum = 0\n",
        "#     for case in f10_test_mbf_mod:\n",
        "#         # can contain it self I think, or there might be zero availble x\n",
        "#         if case == CASE:\n",
        "#             continue\n",
        "#         candidate = True\n",
        "#         count_add = 0\n",
        "#         for i in range(len(case)):\n",
        "#             # because we assume classifier knows adversary will add word in a optimal way, so according to average cost of attack, I set limit to at most 1 word to add\n",
        "#             if count_add > 1:  \n",
        "#                 candidate = False\n",
        "#             if CASE[i] == 0 and case[i] == 1:\n",
        "#                 candidate = False\n",
        "#             else: # can ADD WORDS to case to get CASE\n",
        "#                 if CASE[i] == 1 and case[i] == 0:\n",
        "#                     count_add+=1\n",
        "#         p = 0\n",
        "#         if candidate == True:\n",
        "#             p = 1\n",
        "#             for i in range(N):\n",
        "#                 if case[i] == 1:\n",
        "#                     p *= (word_spam[f10[i]] + 1) / (spam + 2) \n",
        "#                 else:\n",
        "#                     p *= 1   \n",
        "#         sum += p\n",
        "#     p_x_spam_10.append(sum)    \n",
        "\n",
        "# # compute PA(x'|legit)\n",
        "# p_x_legit_10 = []\n",
        "# for case in f10_test_mbf_mod:\n",
        "#     p = 1\n",
        "#     for i in range(N):\n",
        "#         if case[i] == 1:\n",
        "#             p *= (word_legit[f10[i]] + 1) / (legit + 2) \n",
        "#         else:\n",
        "#             p *= 1\n",
        "#     p_x_legit_10.append(p)    \n",
        "\n",
        "\n",
        "\n",
        "# f10_update_pre = []\n",
        "\n",
        "# for i in range(len(f10_test_mbf_mod)):\n",
        "#     psx = p_x_spam_10[i] * p_spam \n",
        "#     p_spam_x_10.append(psx)\n",
        "#     plx = p_x_legit_10[i] * p_legit \n",
        "#     p_legit_x_10.append(plx)\n",
        "#     if psx / plx >=1 :\n",
        "#         f10_update_pre.append(1)\n",
        "#     else:\n",
        "#         f10_update_pre.append(0)"
      ],
      "execution_count": 571,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jWNxxH1g3OtC"
      },
      "source": [
        "# compute PA(x'|legit)\n",
        "p_x_legit_10 = []\n",
        "for case in f10_test_mbf_mod:\n",
        "    p = 1\n",
        "    for i in range(N):\n",
        "        if case[i] == 1:\n",
        "            p *= (word_legit[f10[i]] + 1) / (legit + 2) \n",
        "        else:\n",
        "            p *= 1\n",
        "    p_x_legit_10.append(p) \n",
        "\n",
        "# assume classifier know attack strategy: always add words with minimum cost\n",
        "# compute PA(x'|spam), x' can be generated by any possible x (ADD WORDS), so it is sum of P(x|spam)\n",
        "p_x_spam_10 = []\n",
        "for i in range(len(f10_test_mbf_mod)):\n",
        "    case = f10_test_mbf_mod[i] \n",
        "    sum = 0\n",
        "    for w in sorted_delta[i].keys(): # according to sorted delta(reduction), inversely find optimal original x from x' by remove word with larger delta (greedy)\n",
        "        if case[f_index[w]] == 1: # can remove word\n",
        "            case[f_index[w]] = 0  # remove\n",
        "            psx = 1\n",
        "            plx = 1\n",
        "            for i in range(N):\n",
        "                if case[i] == 1:\n",
        "                    psx *= (word_spam[f10[i]] + 1) / (spam + 2) \n",
        "                else:\n",
        "                    psx *= 1\n",
        "                if case[i] == 1:\n",
        "                    plx *= (word_legit[f10[i]] + 1) / (legit + 2) \n",
        "                else:\n",
        "                    plx *= 1\n",
        "            if psx*p_spam / (plx*p_legit) >= 1: # the original one inversly recover from modified case is spam! we find attacker's original case to modify\n",
        "                sum+=psx\n",
        "                break\n",
        "            else:\n",
        "                 continue\n",
        "    p_x_spam_10.append(sum)\n",
        "\n",
        "f10_update_pre = []\n",
        "\n",
        "for i in range(len(f10_test_mbf_mod)):\n",
        "    psx = p_x_spam_10[i] * p_spam \n",
        "    p_spam_x_10.append(psx)\n",
        "    plx = p_x_legit_10[i] * p_legit \n",
        "    p_legit_x_10.append(plx)\n",
        "    if psx / plx >=1 :\n",
        "        f10_update_pre.append(1)\n",
        "    else:\n",
        "        f10_update_pre.append(0)"
      ],
      "execution_count": 572,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BqSYg5NVrPOh",
        "outputId": "41e8406d-bb08-41f8-cbc9-7bb736be18d3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "# false negative\n",
        "fn_update = 0\n",
        "true_positive = 0\n",
        "for i in range(total):\n",
        "    if test_label[i] == 1 and f10_update_pre[i] == 1 :\n",
        "        true_positive +=1\n",
        "    if test_label[i] == 1 and f10_update_pre[i] == 0:\n",
        "        fn_update+= 1\n",
        "        \n",
        "fnr_update = fn_update / (true_positive + fn_update)  \n",
        "print(\"Flase negative rate after update classifier: \",fnr_update) \n",
        "\n",
        "# false positive\n",
        "fp_update = 0\n",
        "true_negative = 0\n",
        "for i in range(total):\n",
        "    if test_label[i] == 0 and f10_update_pre[i] == 0 :\n",
        "        true_negative +=1\n",
        "    if test_label[i] == 0 and f10_update_pre[i] == 1:\n",
        "        fp_update+= 1\n",
        "        \n",
        "fpr_update = fp_update / (true_negative + fp_update)  \n",
        "print(\"Flase positive rate after update classifier: \",fpr_update) "
      ],
      "execution_count": 573,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Flase negative rate after update classifier:  0.1836734693877551\n",
            "Flase positive rate after update classifier:  0.17768595041322313\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7dljyc6ouF-Q"
      },
      "source": [
        "# Part4 report: adversarial classification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FAERIZXJuIxE",
        "outputId": "4c98006b-5115-4571-c74e-2565443f5ae5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "source": [
        "print(\"Flase negative rate before attacker's modification: \",fnr_before) \n",
        "print(\"Flase negative rate after attacker's modification: \",fnr_after)\n",
        "print(\"average cost of attacker: \", avg_cost)  \n",
        "print(\"Flase negative rate after update classifier: \",fnr_update)   \n",
        "print(\"Flase positive rate after update classifier: \",fpr_update) "
      ],
      "execution_count": 574,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Flase negative rate before attacker's modification:  0.1836734693877551\n",
            "Flase negative rate after attacker's modification:  0.9183673469387755\n",
            "average cost of attacker:  1.469387755102041\n",
            "Flase negative rate after update classifier:  0.1836734693877551\n",
            "Flase positive rate after update classifier:  0.17768595041322313\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}